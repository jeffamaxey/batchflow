

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>batchflow.models.torch.base &mdash; BatchFlow 0.5.0 documentation</title>
  

  
  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/custom.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
        <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
        <script src="../../../../_static/jquery.js"></script>
        <script src="../../../../_static/underscore.js"></script>
        <script src="../../../../_static/doctools.js"></script>
    
    <script type="text/javascript" src="../../../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../../index.html" class="icon icon-home"> BatchFlow
          

          
          </a>

          
            
            
              <div class="version">
                0.5
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../intro/intro.html">A short introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../intro/classes.html">Classes and capabilities</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api/batchflow.html">API</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">BatchFlow</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../../../index.html">Module code</a> &raquo;</li>
        
      <li>batchflow.models.torch.base</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for batchflow.models.torch.base</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot; Eager version of TorchModel. &quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">inspect</span>
<span class="kn">from</span> <span class="nn">threading</span> <span class="kn">import</span> <span class="n">Lock</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">OrderedDict</span>

<span class="kn">import</span> <span class="nn">dill</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>

<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">cupy</span> <span class="k">as</span> <span class="nn">cp</span>
    <span class="n">CUPY_AVAILABLE</span> <span class="o">=</span> <span class="kc">True</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="n">CUPY_AVAILABLE</span> <span class="o">=</span> <span class="kc">False</span>

<span class="kn">from</span> <span class="nn">.initialization</span> <span class="kn">import</span> <span class="n">best_practice_resnet_init</span>
<span class="kn">from</span> <span class="nn">.mixins</span> <span class="kn">import</span> <span class="n">OptimalBatchSizeMixin</span><span class="p">,</span> <span class="n">LayerHook</span><span class="p">,</span> <span class="n">ExtractionMixin</span><span class="p">,</span> <span class="n">VisualizationMixin</span>
<span class="kn">from</span> <span class="nn">.utils</span> <span class="kn">import</span> <span class="n">unpack_fn_from_config</span><span class="p">,</span> <span class="n">get_shape</span>
<span class="kn">from</span> <span class="nn">.layers</span> <span class="kn">import</span> <span class="n">ConvBlock</span>
<span class="kn">from</span> <span class="nn">.losses</span> <span class="kn">import</span> <span class="n">CrossEntropyLoss</span><span class="p">,</span> <span class="n">BinaryLovaszLoss</span><span class="p">,</span> <span class="n">LovaszLoss</span><span class="p">,</span> <span class="n">SSIM</span><span class="p">,</span> <span class="n">MSSIM</span>
<span class="kn">from</span> <span class="nn">.losses</span> <span class="kn">import</span> <span class="n">binary</span> <span class="k">as</span> <span class="n">binary_losses</span><span class="p">,</span> <span class="n">multiclass</span> <span class="k">as</span> <span class="n">multiclass_losses</span>
<span class="kn">from</span> <span class="nn">..base</span> <span class="kn">import</span> <span class="n">BaseModel</span>
<span class="kn">from</span> <span class="nn">...config</span> <span class="kn">import</span> <span class="n">Config</span>



<span class="n">LOSSES</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;l1&#39;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">L1Loss</span><span class="p">,</span>
    <span class="s1">&#39;huber&#39;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">SmoothL1Loss</span><span class="p">,</span>
    <span class="s1">&#39;absolutedifference&#39;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">L1Loss</span><span class="p">,</span>
    <span class="s1">&#39;mse&#39;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">,</span>
    <span class="s1">&#39;cos&#39;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">CosineSimilarity</span><span class="p">,</span>
    <span class="s1">&#39;cosine&#39;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">CosineSimilarity</span><span class="p">,</span>
    <span class="s1">&#39;hinge&#39;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">HingeEmbeddingLoss</span><span class="p">,</span>
    <span class="s1">&#39;ssim&#39;</span><span class="p">:</span> <span class="n">SSIM</span><span class="p">,</span>
    <span class="s1">&#39;mssim&#39;</span><span class="p">:</span> <span class="n">MSSIM</span><span class="p">,</span>

    <span class="s1">&#39;bce&#39;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCEWithLogitsLoss</span><span class="p">,</span>
    <span class="s1">&#39;bdice&#39;</span><span class="p">:</span> <span class="n">binary_losses</span><span class="o">.</span><span class="n">Dice</span><span class="p">,</span>
    <span class="s1">&#39;btversky&#39;</span><span class="p">:</span> <span class="n">binary_losses</span><span class="o">.</span><span class="n">Tversky</span><span class="p">,</span>
    <span class="s1">&#39;blovasz&#39;</span><span class="p">:</span> <span class="n">BinaryLovaszLoss</span><span class="p">,</span>

    <span class="s1">&#39;ce&#39;</span><span class="p">:</span> <span class="n">CrossEntropyLoss</span><span class="p">,</span>
    <span class="s1">&#39;crossentropy&#39;</span><span class="p">:</span> <span class="n">CrossEntropyLoss</span><span class="p">,</span>
    <span class="s1">&#39;logloss&#39;</span><span class="p">:</span> <span class="n">CrossEntropyLoss</span><span class="p">,</span>
    <span class="s1">&#39;dice&#39;</span><span class="p">:</span> <span class="n">multiclass_losses</span><span class="o">.</span><span class="n">Dice</span><span class="p">,</span>
    <span class="s1">&#39;lovasz&#39;</span><span class="p">:</span> <span class="n">LovaszLoss</span>
<span class="p">}</span>

<span class="n">DECAYS</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;exp&#39;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">ExponentialLR</span><span class="p">,</span>
    <span class="s1">&#39;lambda&#39;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">LambdaLR</span><span class="p">,</span>
    <span class="s1">&#39;step&#39;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">StepLR</span><span class="p">,</span>
    <span class="s1">&#39;multistep&#39;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">MultiStepLR</span><span class="p">,</span>
    <span class="s1">&#39;cos&#39;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">CosineAnnealingLR</span><span class="p">,</span>
<span class="p">}</span>

<span class="n">DECAYS_DEFAULTS</span> <span class="o">=</span> <span class="p">{</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">ExponentialLR</span> <span class="p">:</span> <span class="nb">dict</span><span class="p">(</span><span class="n">gamma</span><span class="o">=</span><span class="mf">0.96</span><span class="p">),</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">LambdaLR</span> <span class="p">:</span> <span class="nb">dict</span><span class="p">(</span><span class="n">lr_lambda</span><span class="o">=</span><span class="k">lambda</span> <span class="n">epoch</span><span class="p">:</span> <span class="mf">0.96</span><span class="o">**</span><span class="n">epoch</span><span class="p">),</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">StepLR</span><span class="p">:</span> <span class="nb">dict</span><span class="p">(</span><span class="n">step_size</span><span class="o">=</span><span class="mi">30</span><span class="p">),</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">MultiStepLR</span><span class="p">:</span> <span class="nb">dict</span><span class="p">(</span><span class="n">milestones</span><span class="o">=</span><span class="p">[</span><span class="mi">30</span><span class="p">,</span> <span class="mi">80</span><span class="p">]),</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">CosineAnnealingLR</span><span class="p">:</span> <span class="nb">dict</span><span class="p">(</span><span class="n">T_max</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="p">}</span>


<div class="viewcode-block" id="TorchModel"><a class="viewcode-back" href="../../../../api/batchflow.models.torch.base.html#batchflow.models.torch.base.TorchModel">[docs]</a><span class="k">class</span> <span class="nc">TorchModel</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">,</span> <span class="n">ExtractionMixin</span><span class="p">,</span> <span class="n">OptimalBatchSizeMixin</span><span class="p">,</span> <span class="n">VisualizationMixin</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Base class for Torch models.</span>

<span class="sd">    Implements two main logics:</span>
<span class="sd">        - the first is to build PyTorch model as a sequence of configurable nn.Modules</span>
<span class="sd">        - the second is to make infrastructure for model training, e.g. loss, optimizer and decay,</span>
<span class="sd">        and provide methods for the model training and inference.</span>
<span class="sd">    In the `examples` section you can find a drop-in template for your model.</span>

<span class="sd">    All of the parameters for both logics are defined in the config, supplied at initialization.</span>
<span class="sd">    The detailed description can be seen at `parameters` section; here, we describe the overall structure of keys:</span>
<span class="sd">        - global `cuda` parameters:</span>
<span class="sd">            - `device` sets the desired accelerator to use. Default is to use the single best available (GPU over CPU).</span>
<span class="sd">            - `benchmark` defines the `cuda` behavior: trade some GPU memory to get minor (~15%) acceleration.</span>
<span class="sd">            Default is True.</span>

<span class="sd">        - PyTorch model configuration.</span>
<span class="sd">            - `order` defines the sequence of blocks to build the model from. Default is initial_block -&gt; body -&gt; head.</span>
<span class="sd">            Separation of the NN into multiple blocks is just for convenience, so we can split</span>
<span class="sd">            the preprocessing, main body of the model, and postprocessing into individual parts.</span>
<span class="sd">            In the simplest case, each element is a string that points to other key in the config,</span>
<span class="sd">            which is used to create a :class:`~.torch.layers.ConvBlock`.</span>
<span class="sd">            Check the detailed description for more complex cases.</span>
<span class="sd">            - `initial_block`, `body`, `head` are parameters for this respective parts of the neural network.</span>
<span class="sd">            Defaults are empty layouts, meaning no operations.</span>
<span class="sd">            - `common` parameters are passed to each of the neural network parts. Default is empty.</span>
<span class="sd">            - `output` defines additional operations, applied to the output after loss computation.</span>
<span class="sd">            By default, we have `predictions`, `predictions_{i}` and `predictions_{i}_{j}` aliases.</span>
<span class="sd">            Note that these do not interfere with loss computation and are here only for convenience.</span>
<span class="sd">            - `init_weights` allows to initialize weights.</span>

<span class="sd">        - shapes info. If fully provided, used to initialize the model. If no shapes are given in the config,</span>
<span class="sd">        the model is created at the time of the first `train` call by looking at the actual batch data and shapes.</span>
<span class="sd">        Keys are `inputs_shapes`, `targets_shapes`, `classes`, and `placeholder_batch_size`.</span>
<span class="sd">        By default, no shapes are set in the config.</span>

<span class="sd">        - train and inference common parameters:</span>
<span class="sd">            - `amp` turns on/off automatic mixed precision, which allows to perform some of the operations in `float16`.</span>
<span class="sd">            Default is True.</span>
<span class="sd">            - `microbatch_size` allows to split the training/inference batches in chunks (microbatches) and process</span>
<span class="sd">            them sequentially. During train, we apply gradients only after all microbatches from the batch are used.</span>
<span class="sd">            Default is to not use microbatching.</span>

<span class="sd">        - train only parameters:</span>
<span class="sd">            - `sync_frequency` to apply gradients only once in a `sync_frequency` calls to `train` method.</span>
<span class="sd">            Default is to apply gradients after each `train` iteration.</span>
<span class="sd">            - `callbacks` to apply operations at the end of each iteration. Default is no callbacks.</span>
<span class="sd">            - `sam_rho`, `sam_individual_norm` to use sharpness-aware minimization. Default is to not use SAM at all.</span>
<span class="sd">            - `profile` to get detailed report of model performance. Default is False.</span>

<span class="sd">        - infrastructure for training:</span>
<span class="sd">            - `loss`. No default value, so this key is required.</span>
<span class="sd">            - `optimizer`. Default is `Adam`.</span>
<span class="sd">            - `decay`. Default is to not use learning rate decay.</span>


<span class="sd">    We recommend looking at :class:`~.torch.layers.ConvBlock` to learn about parameters for model building blocks,</span>
<span class="sd">    and at :class:`~.EncoderDecoder` which allows more sophisticated logic of block chaining.</span>


<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    config : dict, :class:`~Config`</span>
<span class="sd">        Configuration of model creation. Below are the valid keys.</span>

<span class="sd">    # Global parameters</span>
<span class="sd">    device : str, torch.device or sequence</span>
<span class="sd">        Device to use for model, training and inference.</span>
<span class="sd">        If str, a device name (e.g. ``&#39;cpu&#39;`` or ``&#39;gpu:0&#39;``). Regular expressions are also allowed (e.g. ``&#39;gpu:*&#39;``).</span>
<span class="sd">        If torch.device, then device to be used.</span>
<span class="sd">        If sequence, then each entry must be in one of previous formats, and batch data is paralleled across them.</span>
<span class="sd">        Default behaviour is to use one (and only one) device of the best available type (priority to GPU over CPU).</span>

<span class="sd">    benchmark : bool</span>
<span class="sd">        Whether to optimize network&#39;s forward pass during the first batch.</span>
<span class="sd">        Leverages the memory-speed trade-off: the network may use more GPU memory to compute predictions faster.</span>
<span class="sd">        Speeds up the forward pass by ~15% if shapes of inputs are constant.</span>
<span class="sd">        Make sure not to use different shapes of inputs.</span>


<span class="sd">    # Model building configuration</span>
<span class="sd">    order : sequence</span>
<span class="sd">        Defines sequence of network blocks in the architecture. Default is initial_block -&gt; body -&gt; head.</span>
<span class="sd">        Each element of the sequence must be either a string, a tuple or a dict.</span>
<span class="sd">        If string, then it is used as name of method to use, as config key to use, as name in model repr.</span>
<span class="sd">        For example, ``&#39;initial_block&#39;`` stands for using ``self.initial_block`` with config[`initial_block`]</span>
<span class="sd">        as parameters, and model representation would show this part of network as `initial_block`.</span>
<span class="sd">        If tuple, then it must have three elements: (block_name, config_name, method).</span>
<span class="sd">        If dict, then it must contain three keys: `block_name`, `config_name`, `method`.</span>
<span class="sd">        In cases of tuple and dict, `method` can also be callable.</span>

<span class="sd">    initial_block : dict</span>
<span class="sd">        User-defined module or parameters for the input block, usually :class:`~.torch.layers.ConvBlock` parameters.</span>

<span class="sd">        Examples:</span>

<span class="sd">        - ``{&#39;initial_block&#39;: dict(layout=&#39;nac nac&#39;, filters=64, kernel_size=[7, 3], strides=[1, 2])}``</span>
<span class="sd">        - ``{&#39;initial_block&#39;: MyCustomModule(some_param=1, another_param=2)}``</span>

<span class="sd">    body : dict or nn.Module</span>
<span class="sd">        User-defined module or parameters for the base network layers,</span>
<span class="sd">        usually :class:`~.torch.layers.ConvBlock` parameters.</span>

<span class="sd">    head : dict or nn.Module</span>
<span class="sd">        User-defined module or parameters for the prediction layers,</span>
<span class="sd">        usually :class:`~.torch.layers.ConvBlock` parameters.</span>

<span class="sd">    common : dict</span>
<span class="sd">        Default parameters for all blocks (see :class:`~.torch.layers.ConvBlock`).</span>

<span class="sd">    output : str, list or dict</span>
<span class="sd">        Auxiliary operations to apply to the network predictions.</span>
<span class="sd">        If dict, then should have the same length and order as network predictions.</span>
<span class="sd">        Each key defines this prediction name, each value should be a str/list of operations to apply to this tensor.</span>
<span class="sd">        For example, ``{&#39;my_prediction&#39; : [&#39;sigmoid&#39;, my_callable, &#39;softmax]}``.</span>
<span class="sd">        Generated outputs are available as `my_prediction_{j}`, `my_prediction_sigmoid`,</span>
<span class="sd">        and also by alias `predictions_{i}_{j}`, where `i` is the tensor ordinal and `j` is operation ordinal.</span>

<span class="sd">        If list or str, then default prefix `&#39;&#39;` is used.</span>
<span class="sd">        See :meth:`.TorchModel.output` for more details.</span>

<span class="sd">    init_weights : callable, &#39;best_practice_resnet&#39;, or None</span>
<span class="sd">        Model weights initilaization.</span>
<span class="sd">        If None, then default initialization is used.</span>
<span class="sd">        If &#39;best_practice_resnet&#39;, then common used non-default initialization is used.</span>
<span class="sd">        If callable, then callable applied to each layer.</span>

<span class="sd">        Examples:</span>

<span class="sd">        - ``{&#39;init_weights&#39;: &#39;best_practice_resnet&#39;}``</span>
<span class="sd">        - .. code-block:: python</span>

<span class="sd">            def callable_init(module): # example of a callable for init</span>
<span class="sd">                if isinstance(module, nn.Linear):</span>
<span class="sd">                    nn.kaiming_normal_(module.weight)</span>

<span class="sd">            config = {&#39;init_weights&#39;: callable_init}</span>


<span class="sd">    # Shapes: optional</span>
<span class="sd">    inputs_shapes : sequence</span>
<span class="sd">        Shapes of the input tensors without the batch size.</span>
<span class="sd">        Must be a tuple (one input) or sequence of tuples (multiple inputs) with shapes.</span>

<span class="sd">    targets_shapes : sequence</span>
<span class="sd">        Shapes of the target tensors without the batch size.</span>
<span class="sd">        Must be a tuple (one target) or sequence of tuples (multiple targets) with shapes.</span>
<span class="sd">        Available as `targets_shapes` parameter in the `head` block.</span>

<span class="sd">    classes : int or sequence of ints</span>
<span class="sd">        Number of desired classes in the output tensor. Available as `classes` parameter in the `head` block.</span>

<span class="sd">    placeholder_batch_size : int</span>
<span class="sd">        If `inputs` is specified with all the required shapes, then it serves as size of batch dimension during</span>
<span class="sd">        placeholder (usually np.ndarrays with zeros) creation. Default value is 2.</span>


<span class="sd">    # Train and inference behavior</span>
<span class="sd">    amp : bool</span>
<span class="sd">        Whether to use automated mixed precision during model training and inference. Default is True.</span>
<span class="sd">        The output type of predictions remains float32. Can be changed in `train` and `predict` arguments.</span>

<span class="sd">    microbatch_size : int, bool or None</span>
<span class="sd">        Also known as virtual batch. Allows to process given data sequentially,</span>
<span class="sd">        accumulating gradients from microbatches and applying them once in the end.</span>
<span class="sd">        If int, then size of chunks to split every batch into.</span>
<span class="sd">        If False or None, then this feature is not used. Default is not to use microbatching.</span>
<span class="sd">        Can be changed in `train` and `predict` arguments.</span>


<span class="sd">    # Additional train modifications</span>
<span class="sd">    sync_frequency : int</span>
<span class="sd">        How often to apply accumulated gradients to the weights. Default value is to apply them after each batch.</span>
<span class="sd">        Can be changed in `train` and `predict` arguments.</span>

<span class="sd">    callbacks : sequence of `:class:callbacks.BaseCallback`</span>
<span class="sd">        Callbacks to call at the end of each training iteration.</span>

<span class="sd">    sam_rho : float</span>
<span class="sd">        Foret P. et al. &quot;`Sharpness-Aware Minimization for Efficiently Improving Generalization</span>
<span class="sd">        &lt;https://arxiv.org/abs/2010.01412&gt;`_&quot;.</span>
<span class="sd">        If evaluates to False, then SAM is not used.</span>
<span class="sd">        If float, then controls the size of neighborhood (check the paper for details).</span>
<span class="sd">    sam_individual_norm : bool</span>
<span class="sd">        If True, then each gradient is scaled according to its own L2 norm.</span>
<span class="sd">        If False, then one common gradient norm is computed and used as a scaler for all gradients.</span>

<span class="sd">    profile : bool</span>
<span class="sd">        Whether to collect stats of model training timings.</span>
<span class="sd">        If True, then stats can be accessed via `profile_info` attribute or :meth:`.show_profile_info` method.</span>


<span class="sd">    # Infrastructure</span>
<span class="sd">    loss : str, dict</span>
<span class="sd">        Loss function, might be defined in multiple formats.</span>

<span class="sd">        If str, then short ``name``.</span>
<span class="sd">        If dict, then ``{&#39;name&#39;: name, **kwargs}``.</span>

<span class="sd">        Name must be one of:</span>
<span class="sd">            - short name (e.g. ``&#39;mse&#39;``, ``&#39;ce&#39;``, ``&#39;l1&#39;``, ``&#39;cos&#39;``, ``&#39;hinge&#39;``,</span>
<span class="sd">              ``&#39;huber&#39;``, ``&#39;logloss&#39;``, ``&#39;dice&#39;``)</span>
<span class="sd">            - a class name from `torch losses &lt;https://pytorch.org/docs/stable/nn.html#loss-functions&gt;`_</span>
<span class="sd">              (e.g. ``&#39;PoissonNLL&#39;`` or ``&#39;TripletMargin&#39;``)</span>
<span class="sd">            - an instance or constructor of `:class:torch.nn.Module`</span>
<span class="sd">            - callable</span>

<span class="sd">        Examples:</span>

<span class="sd">        - ``{&#39;loss&#39;: &#39;mse&#39;}``</span>
<span class="sd">        - ``{&#39;loss&#39;: {&#39;name&#39;: &#39;KLDiv&#39;, &#39;reduction&#39;: &#39;none&#39;}}``</span>
<span class="sd">        - ``{&#39;loss&#39;: {&#39;name&#39;: MyCustomLoss, &#39;epsilon&#39;: 1e-6}}``</span>
<span class="sd">        - ``{&#39;loss&#39;: my_custom_loss_fn}``</span>
<span class="sd">        - ``{&#39;loss&#39;: my_custom_loss_class}``</span>

<span class="sd">    optimizer : str, dict</span>
<span class="sd">        Optimizer, might be defined in multiple formats.</span>

<span class="sd">        If str, then short ``name``.</span>
<span class="sd">        If dict, then ``{&#39;name&#39;: name, **kwargs}``.</span>

<span class="sd">        Name must be one of:</span>
<span class="sd">            - short name (e.g. ``&#39;Adam&#39;``, ``&#39;Adagrad&#39;``, any optimizer from</span>
<span class="sd">              `torch.optim &lt;https://pytorch.org/docs/stable/optim.html#algorithms&gt;`_)</span>
<span class="sd">            - a class with ``Optimizer`` interface</span>
<span class="sd">            - a callable which takes model parameters and optional args</span>

<span class="sd">        Examples:</span>

<span class="sd">        - ``{&#39;optimizer&#39;: &#39;Adam&#39;}``</span>
<span class="sd">        - ``{&#39;optimizer&#39;: {&#39;name&#39;: &#39;SparseAdam&#39;, &#39;lr&#39;: 0.01}}``</span>
<span class="sd">        - ``{&#39;optimizer&#39;: {&#39;name&#39;: &#39;Adagrad&#39;, &#39;initial_accumulator_value&#39;: 0.01}}``</span>
<span class="sd">        - ``{&#39;optimizer&#39;: {&#39;name&#39;: MyCustomOptimizer, &#39;momentum&#39;: 0.95}}``</span>

<span class="sd">    decay : dict, list of dicts</span>
<span class="sd">        The learning rate decay algorithm might be defined in multiple formats.</span>
<span class="sd">        All decays require to have &#39;frequency&#39; as a key in a configuration dictionary.</span>
<span class="sd">        Parameter &#39;frequency&#39; sets how often do decay step: at every `&#39;frequency&#39;`</span>
<span class="sd">        iteration. Each decay might have optional parameters &#39;first_iter&#39; and &#39;last_iter&#39;</span>
<span class="sd">        that defines the closed range of iterations where decay is at work.</span>
<span class="sd">        If you want to use a learning rate warmup and decay together,</span>
<span class="sd">        you should use a list of decays (see examples).</span>

<span class="sd">        If dict, then ``{&#39;name&#39;: name, **kwargs}``.</span>
<span class="sd">        If list, then each item is a dict of format described above.</span>

<span class="sd">        Name must be one of:</span>

<span class="sd">        - a class name from `torch.optim.lr_scheduler</span>
<span class="sd">          &lt;https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate&gt;`_</span>
<span class="sd">          (e.g. ``&#39;LambdaLR&#39;``) except ``&#39;ReduceLROnPlateau&#39;``.</span>
<span class="sd">        - short name (``&#39;exp&#39;`` - ExponentialLR, ``&#39;lambda&#39;`` - LambdaLR, ``&#39;step&#39;`` - StepLR,</span>
<span class="sd">                      ``&#39;multistep&#39;`` - MultiStepLR, ``&#39;cos&#39;`` - CosineAnnealingLR)</span>
<span class="sd">        - a class with ``_LRScheduler`` interface</span>
<span class="sd">        - a callable which takes optimizer and optional args</span>

<span class="sd">        Examples:</span>

<span class="sd">        - ``{&#39;decay&#39;: {&#39;name: &#39;exp&#39;, &#39;frequency&#39;: 5, &#39;first_iter&#39;: 6, &#39;last_iter&#39;: 20}}``</span>
<span class="sd">        - ``{&#39;decay&#39;: {&#39;name&#39;: &#39;StepLR&#39;, &#39;steps_size&#39;: 10000, &#39;frequency&#39;: 5}}``</span>
<span class="sd">        - ``{&#39;decay&#39;: {&#39;name&#39;: MyCustomDecay, &#39;decay_rate&#39;: .5, &#39;frequency&#39;: 15, &#39;first_iter&#39;: 400}``</span>
<span class="sd">        - .. code-block:: python</span>

<span class="sd">            {&#39;decay&#39;: [{&#39;name&#39;: &#39;exp&#39;, &#39;gamma&#39;: 1, &#39;frequency&#39;: 1, &#39;last_iter&#39;: 900},</span>
<span class="sd">                       {&#39;name&#39;: &#39;exp&#39;, &#39;gamma&#39;: 0.96, &#39;frequency&#39;: 2, &#39;first_iter&#39;: 901}]</span>


<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    segmentation_config = {</span>
<span class="sd">        # Model layout</span>
<span class="sd">        &#39;initial_block&#39;: {&#39;layout&#39;: &#39;cna cna cnap&#39;,                    # string layout: c=conv, n=BN, a=act, p=pool</span>
<span class="sd">                          filters: [INT, INT, INT],                    # individual filters for each convolution</span>
<span class="sd">                          &#39;kernel_size&#39;: 3},                           # common kernel_size for all convolutions</span>

<span class="sd">        &#39;body&#39;: {&#39;base_block&#39;: ResBlock,                               # in ConvBlock, we can use any nn.Module as base</span>
<span class="sd">                 &#39;filters&#39;: INT, &#39;kernel_size&#39;: INT,</span>
<span class="sd">                 &#39;downsample&#39;: False, &#39;attention&#39;: &#39;scse&#39;},            # additional parameters of ResBlock module</span>

<span class="sd">        &#39;head&#39;: {&#39;layout&#39; : &#39;cna&#39;, &#39;filters&#39;: 1},                      # postprocessing</span>
<span class="sd">        &#39;output&#39;: &#39;sigmoid&#39;,                                           # can get `sigmoid` output in the `predict`</span>

<span class="sd">        # Train configuration</span>
<span class="sd">        &#39;loss&#39;: &#39;bdice&#39;,                                               # binary dice coefficient as loss function</span>
<span class="sd">        &#39;optimizer&#39;: {&#39;name&#39;: &#39;Adam&#39;, &#39;lr&#39;: 0.01,},</span>
<span class="sd">        &#39;decay&#39;: {&#39;name&#39;: &#39;exp&#39;, &#39;gamma&#39;: 0.9, &#39;frequency&#39;: 100},</span>
<span class="sd">        &#39;microbatch_size&#39;: 16,                                         # size of microbatches at training</span>
<span class="sd">    }</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">PRESERVE</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s1">&#39;full_config&#39;</span><span class="p">,</span> <span class="s1">&#39;config&#39;</span><span class="p">,</span> <span class="s1">&#39;model&#39;</span><span class="p">,</span>
        <span class="s1">&#39;inputs_shapes&#39;</span><span class="p">,</span> <span class="s1">&#39;targets_shapes&#39;</span><span class="p">,</span> <span class="s1">&#39;classes&#39;</span><span class="p">,</span>
        <span class="s1">&#39;loss&#39;</span><span class="p">,</span> <span class="s1">&#39;optimizer&#39;</span><span class="p">,</span> <span class="s1">&#39;decay&#39;</span><span class="p">,</span> <span class="s1">&#39;decay_step&#39;</span><span class="p">,</span>
        <span class="s1">&#39;sync_counter&#39;</span><span class="p">,</span> <span class="s1">&#39;microbatch_size&#39;</span><span class="p">,</span>
        <span class="s1">&#39;iteration&#39;</span><span class="p">,</span> <span class="s1">&#39;last_train_info&#39;</span><span class="p">,</span> <span class="s1">&#39;last_predict_info&#39;</span><span class="p">,</span>
        <span class="s1">&#39;lr_list&#39;</span><span class="p">,</span> <span class="s1">&#39;syncs&#39;</span><span class="p">,</span> <span class="s1">&#39;decay_iters&#39;</span><span class="p">,</span>
        <span class="s1">&#39;_loss_list&#39;</span><span class="p">,</span> <span class="s1">&#39;loss_list&#39;</span><span class="p">,</span> <span class="s1">&#39;operations&#39;</span>
    <span class="p">]</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">full_config</span> <span class="o">=</span> <span class="n">Config</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_lock</span> <span class="o">=</span> <span class="n">Lock</span><span class="p">()</span>

        <span class="c1"># Shapes of inputs and targets</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">placeholder_batch_size</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inputs_shapes</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">targets_shapes</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">classes</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># Pytorch model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># Leading device and list of all devices to use</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">devices</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># Train procedure and ifrastructure</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init_weights</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decay</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decay_step</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">amp</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scaler</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">operations</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># Memory amortization: accumulate gradients to update weights later</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sync_frequency</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sync_counter</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">microbatch_size</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># Sharpness-aware minimization</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sam_rho</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sam_individual_norm</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="c1"># Store info about passed train/predict iterations</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">iteration</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">last_train_info</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">last_predict_info</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lr_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">syncs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decay_iters</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_loss_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_list</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># Profile kernels used</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">profile</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">profilers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">profile_info</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># Store the config for later usage</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">external_config</span> <span class="o">=</span> <span class="n">Config</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>

        <span class="c1">#</span>
        <span class="n">load</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">external_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;load&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">load</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="o">**</span><span class="n">load</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">initialize</span><span class="p">()</span>


<div class="viewcode-block" id="TorchModel.initialize"><a class="viewcode-back" href="../../../../api/batchflow.models.torch.base.html#batchflow.models.torch.base.TorchModel.initialize">[docs]</a>    <span class="k">def</span> <span class="nf">initialize</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Initialize the instance: make the config, attributes, and, if possible, PyTorch model. &quot;&quot;&quot;</span>
        <span class="c1"># Create config from default and external one</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">combine_configs</span><span class="p">()</span>

        <span class="c1"># First, extract all necessary info from config into the instance attributes.</span>
        <span class="c1"># Then, update config with some of parsed values -- mainly for convenience.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">parse_attributes</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">update_config</span><span class="p">()</span>

        <span class="c1"># If the inputs are set in config with their shapes we can build right away</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">inputs_shapes</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">build_model</span><span class="p">()</span></div>

<div class="viewcode-block" id="TorchModel.reset"><a class="viewcode-back" href="../../../../api/batchflow.models.torch.base.html#batchflow.models.torch.base.TorchModel.reset">[docs]</a>    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Delete the underlying model and all the infrastructure. Use to create model from scratch. &quot;&quot;&quot;</span>
        <span class="c1"># TODO: do we really need this?</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">last_train_info</span> <span class="o">=</span> <span class="p">{}</span></div>


    <span class="c1"># Create config of model creation: combine the external and default ones</span>
<div class="viewcode-block" id="TorchModel.default_config"><a class="viewcode-back" href="../../../../api/batchflow.models.torch.base.html#batchflow.models.torch.base.TorchModel.default_config">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">default_config</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Define model defaults.</span>

<span class="sd">        Put here all constants (like the number of filters, kernel sizes, block layouts, strides, etc)</span>
<span class="sd">        specific to the model, but independent of anything else (like image shapes, number of classes, etc).</span>

<span class="sd">        Don&#39;t forget to use the default config from parent class.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">config</span> <span class="o">=</span> <span class="n">Config</span><span class="p">({</span>
            <span class="c1"># Devices and memory control</span>
            <span class="s1">&#39;amp&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
            <span class="s1">&#39;device&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
            <span class="s1">&#39;benchmark&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
            <span class="s1">&#39;microbatch_size&#39;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
            <span class="s1">&#39;sync_frequency&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
            <span class="s1">&#39;profile&#39;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>

            <span class="c1"># Model building</span>
            <span class="s1">&#39;order&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;initial_block&#39;</span><span class="p">,</span> <span class="s1">&#39;body&#39;</span><span class="p">,</span> <span class="s1">&#39;head&#39;</span><span class="p">],</span>
            <span class="s1">&#39;initial_block&#39;</span><span class="p">:</span> <span class="p">{},</span>
            <span class="s1">&#39;body&#39;</span><span class="p">:</span> <span class="p">{},</span>
            <span class="s1">&#39;head&#39;</span><span class="p">:</span> <span class="p">{},</span>
            <span class="s1">&#39;common&#39;</span><span class="p">:</span> <span class="p">{},</span>

            <span class="c1"># Additional operations to apply to model predictions</span>
            <span class="s1">&#39;output&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>

            <span class="c1"># Shapes</span>
            <span class="s1">&#39;placeholder_batch_size&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>

            <span class="c1"># Training infrastructure</span>
            <span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
            <span class="s1">&#39;optimizer&#39;</span><span class="p">:</span> <span class="s1">&#39;Adam&#39;</span><span class="p">,</span>
            <span class="s1">&#39;decay&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>

            <span class="c1"># SAM: sharpness-aware minimization</span>
            <span class="s1">&#39;sam_rho&#39;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span>
            <span class="s1">&#39;sam_individual_norm&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
        <span class="p">})</span>
        <span class="k">return</span> <span class="n">config</span></div>

<div class="viewcode-block" id="TorchModel.combine_configs"><a class="viewcode-back" href="../../../../api/batchflow.models.torch.base.html#batchflow.models.torch.base.TorchModel.combine_configs">[docs]</a>    <span class="k">def</span> <span class="nf">combine_configs</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Combine default configuration and the external one. &quot;&quot;&quot;</span>
        <span class="n">config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">default_config</span><span class="p">()</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">external_config</span>
        <span class="k">return</span> <span class="n">config</span></div>

<div class="viewcode-block" id="TorchModel.update_config"><a class="viewcode-back" href="../../../../api/batchflow.models.torch.base.html#batchflow.models.torch.base.TorchModel.update_config">[docs]</a>    <span class="k">def</span> <span class="nf">update_config</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Update config with instance attributes. &quot;&quot;&quot;</span>
        <span class="n">config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span>

        <span class="n">config</span><span class="p">[</span><span class="s1">&#39;head/targets_shapes&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">targets_shapes</span>
        <span class="c1"># As `update_config` can be called multiple times, and `head/classes` key can have value `None`,</span>
        <span class="c1"># we need to use `or` insetad of `get`</span>
        <span class="n">config</span><span class="p">[</span><span class="s1">&#39;head/classes&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;head/classes&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">classes</span>

        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;head/units&#39;</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">config</span><span class="p">[</span><span class="s1">&#39;head/units&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;head/classes&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;head/filters&#39;</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">config</span><span class="p">[</span><span class="s1">&#39;head/filters&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;head/classes&#39;</span><span class="p">)</span></div>


    <span class="c1"># Parse config keys into instance attributes</span>
<div class="viewcode-block" id="TorchModel.parse_attributes"><a class="viewcode-back" href="../../../../api/batchflow.models.torch.base.html#batchflow.models.torch.base.TorchModel.parse_attributes">[docs]</a>    <span class="k">def</span> <span class="nf">parse_attributes</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Parse instance attributes from config. &quot;&quot;&quot;</span>
        <span class="n">config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">init_weights</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;init_weights&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">microbatch_size</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;microbatch&#39;</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;microbatch_size&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sync_frequency</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;sync_frequency&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">amp</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;amp&#39;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">sam_rho</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;sam_rho&#39;</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sam_individual_norm</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;sam_individual_norm&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">profile</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;profile&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span><span class="n">callback</span><span class="o">.</span><span class="n">set_model</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="k">for</span> <span class="n">callback</span> <span class="ow">in</span> <span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;callbacks&#39;</span><span class="p">,</span> <span class="p">[])]</span>

        <span class="c1"># Parse operations, that should be applied to model predictions, into a dictionary</span>
        <span class="n">operations</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;output&#39;</span><span class="p">]</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">operations</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="n">operations</span> <span class="o">=</span> <span class="n">operations</span> <span class="ow">or</span> <span class="p">[]</span>
            <span class="n">operations</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">operations</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">operations</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">))</span> <span class="k">else</span> <span class="p">[</span><span class="n">operations</span><span class="p">]</span>
            <span class="n">operations</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;&#39;</span> <span class="p">:</span> <span class="n">operations</span><span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">operations</span> <span class="o">=</span> <span class="n">operations</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_parse_devices</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_parse_placeholder_shapes</span><span class="p">()</span></div>


    <span class="k">def</span> <span class="nf">_parse_devices</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Extract `devices` and `benchmark` from config.</span>
<span class="sd">        If the config value is not set, use the best available accelerator.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">external_config</span>
        <span class="n">devices</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;device&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">devices</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">devices</span> <span class="o">=</span> <span class="n">devices</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">devices</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="k">else</span> <span class="p">[</span><span class="n">devices</span><span class="p">]</span>
            <span class="n">available_devices</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;cuda:</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device_count</span><span class="p">())]</span> <span class="o">+</span> <span class="p">[</span><span class="s1">&#39;cpu&#39;</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">dev</span> <span class="ow">in</span> <span class="n">devices</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dev</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">):</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">devices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dev</span><span class="p">)</span>
                <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dev</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                    <span class="n">dev_</span> <span class="o">=</span> <span class="n">dev</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
                    <span class="n">dev_</span> <span class="o">=</span> <span class="n">dev_</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;gpu&#39;</span><span class="p">,</span> <span class="s1">&#39;cuda&#39;</span><span class="p">)</span>
                    <span class="n">dev_</span> <span class="o">=</span> <span class="n">dev_</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;cpu:0&#39;</span><span class="p">,</span> <span class="s1">&#39;cpu&#39;</span><span class="p">)</span>

                    <span class="n">devices</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">device</span> <span class="ow">in</span> <span class="n">available_devices</span>
                               <span class="k">if</span> <span class="n">re</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="n">dev_</span><span class="p">,</span> <span class="n">device</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">]</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">devices</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">devices</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;Wrong device type: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">dev</span><span class="p">)))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">devices</span> <span class="o">=</span> <span class="p">[</span><span class="n">device</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">device</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">devices</span><span class="p">)</span>
                            <span class="k">if</span> <span class="n">device</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">devices</span><span class="p">[:</span><span class="n">i</span><span class="p">]]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">devices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">benchmark</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;benchmark&#39;</span><span class="p">,</span> <span class="s1">&#39;cuda&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_parse_placeholder_shapes</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Extract `inputs_shapes`, `targets_shapes`, `classes` from config. &quot;&quot;&quot;</span>
        <span class="n">config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span>

        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;placeholder_batch_size&#39;</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">inputs_shapes</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;inputs_shapes&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;input_shapes&#39;</span><span class="p">)</span>
        <span class="n">targets_shapes</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;targets_shapes&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;target_shapes&#39;</span><span class="p">)</span>
        <span class="n">classes</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;classes&#39;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">placeholder_batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>

        <span class="k">if</span> <span class="n">inputs_shapes</span><span class="p">:</span>
            <span class="n">inputs_shapes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_to_nested_list</span><span class="p">(</span><span class="n">inputs_shapes</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">inputs_shapes</span> <span class="o">=</span> <span class="p">[(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">*</span><span class="n">shape</span><span class="p">)</span> <span class="k">for</span> <span class="n">shape</span> <span class="ow">in</span> <span class="n">inputs_shapes</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">targets_shapes</span><span class="p">:</span>
            <span class="n">targets_shapes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_to_nested_list</span><span class="p">(</span><span class="n">targets_shapes</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">targets_shapes</span> <span class="o">=</span> <span class="p">[(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">*</span><span class="n">shape</span><span class="p">)</span> <span class="k">for</span> <span class="n">shape</span> <span class="ow">in</span> <span class="n">targets_shapes</span><span class="p">]</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="n">classes</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">classes</span> <span class="o">=</span> <span class="p">[</span><span class="n">item</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">targets_shapes</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">classes</span><span class="p">:</span>
            <span class="n">classes</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">classes</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">classes</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">))</span> <span class="k">else</span> <span class="p">[</span><span class="n">classes</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">classes</span> <span class="o">=</span> <span class="n">classes</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_to_nested_list</span><span class="p">(</span><span class="n">sequence</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">sequence</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">)):</span>
            <span class="k">return</span> <span class="p">[</span><span class="nb">list</span><span class="p">(</span><span class="n">sequence</span><span class="p">)]</span>
        <span class="k">return</span> <span class="p">[</span><span class="nb">list</span><span class="p">(</span><span class="n">item</span><span class="p">)</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">sequence</span><span class="p">]</span>

<div class="viewcode-block" id="TorchModel.make_placeholder_data"><a class="viewcode-back" href="../../../../api/batchflow.models.torch.base.html#batchflow.models.torch.base.TorchModel.make_placeholder_data">[docs]</a>    <span class="k">def</span> <span class="nf">make_placeholder_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Create a sequence of tensor, based on the parsed `inputs_shapes`. &quot;&quot;&quot;</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">placeholder_batch_size</span>

        <span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">*</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">shape</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">inputs_shapes</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">data</span></div>


    <span class="c1"># Create training infrastructure: loss, optimizer, decay</span>
<div class="viewcode-block" id="TorchModel.make_infrastructure"><a class="viewcode-back" href="../../../../api/batchflow.models.torch.base.html#batchflow.models.torch.base.TorchModel.make_infrastructure">[docs]</a>    <span class="k">def</span> <span class="nf">make_infrastructure</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Create loss, optimizer and decay, required for training the model. &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">make_loss</span><span class="p">(</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">_unpack</span><span class="p">(</span><span class="s1">&#39;loss&#39;</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">make_optimizer</span><span class="p">(</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">_unpack</span><span class="p">(</span><span class="s1">&#39;optimizer&#39;</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">make_decay</span><span class="p">(</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">_unpack</span><span class="p">(</span><span class="s1">&#39;decay&#39;</span><span class="p">),</span> <span class="n">optimizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scaler</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">amp</span><span class="o">.</span><span class="n">GradScaler</span><span class="p">()</span></div>

    <span class="k">def</span> <span class="nf">_unpack</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Get params from config. &quot;&quot;&quot;</span>
        <span class="c1"># TODO: move all code here to make it more explicit</span>
        <span class="n">unpacked</span> <span class="o">=</span> <span class="n">unpack_fn_from_config</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">unpacked</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="k">return</span> <span class="p">{</span><span class="n">name</span><span class="p">:</span> <span class="n">unpacked</span><span class="p">}</span>
        <span class="n">key</span><span class="p">,</span> <span class="n">kwargs</span> <span class="o">=</span> <span class="n">unpacked</span>
        <span class="k">return</span> <span class="p">{</span><span class="n">name</span><span class="p">:</span> <span class="n">key</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">}</span>

<div class="viewcode-block" id="TorchModel.make_loss"><a class="viewcode-back" href="../../../../api/batchflow.models.torch.base.html#batchflow.models.torch.base.TorchModel.make_loss">[docs]</a>    <span class="k">def</span> <span class="nf">make_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Set model loss. Changes the `loss` attribute. &quot;&quot;&quot;</span>
        <span class="n">loss_fn</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="c1"># Parse `loss` to actual module</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="c1"># String like &#39;ce&#39;, &#39;bdice&#39; or &#39;CrossEntropy&#39;</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">nn</span><span class="p">,</span> <span class="n">loss</span><span class="p">):</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">nn</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
            <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">nn</span><span class="p">,</span> <span class="n">loss</span> <span class="o">+</span> <span class="s2">&quot;Loss&quot;</span><span class="p">):</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">nn</span><span class="p">,</span> <span class="n">loss</span> <span class="o">+</span> <span class="s2">&quot;Loss&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">LOSSES</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s1">&#39;[-_ ]&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">(),</span> <span class="kc">None</span><span class="p">)</span>

        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
            <span class="c1"># Already a valid module</span>
            <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">loss</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="nb">type</span><span class="p">):</span>
            <span class="c1"># Class to make module</span>
            <span class="k">pass</span>
        <span class="k">elif</span> <span class="n">callable</span><span class="p">(</span><span class="n">loss</span><span class="p">):</span>
            <span class="c1"># Callable: just pass other arguments in</span>
            <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Loss is not defined in the model </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">)</span>

        <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">loss_fn</span> <span class="ow">or</span> <span class="n">loss</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">loss_fn</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
            <span class="n">loss_fn</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span></div>

<div class="viewcode-block" id="TorchModel.make_optimizer"><a class="viewcode-back" href="../../../../api/batchflow.models.torch.base.html#batchflow.models.torch.base.TorchModel.make_optimizer">[docs]</a>    <span class="k">def</span> <span class="nf">make_optimizer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Set model optimizer. Changes the `optimizer` attribute. &quot;&quot;&quot;</span>
        <span class="c1"># Choose the optimizer</span>
        <span class="k">if</span> <span class="n">callable</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="nb">type</span><span class="p">):</span>
            <span class="k">pass</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">):</span>
            <span class="n">optimizer</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Unknown optimizer&quot;</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

<div class="viewcode-block" id="TorchModel.make_decay"><a class="viewcode-back" href="../../../../api/batchflow.models.torch.base.html#batchflow.models.torch.base.TorchModel.make_decay">[docs]</a>    <span class="k">def</span> <span class="nf">make_decay</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">decay</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Set model decay. Changes the `decay` and `decay_step` attribute. &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">decay</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">)):</span>
            <span class="n">decays</span> <span class="o">=</span> <span class="n">decay</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">decays</span> <span class="o">=</span> <span class="p">[(</span><span class="n">decay</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">)]</span> <span class="k">if</span> <span class="n">decay</span> <span class="k">else</span> <span class="p">[]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">decay</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">decay_step</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">decay_</span><span class="p">,</span> <span class="n">decay_kwargs</span> <span class="ow">in</span> <span class="n">decays</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">decay_</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Missing `name` key in the decay configuration&#39;</span><span class="p">)</span>

            <span class="c1"># Parse decay</span>
            <span class="k">if</span> <span class="n">callable</span><span class="p">(</span><span class="n">decay_</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">decay_</span><span class="p">,</span> <span class="nb">type</span><span class="p">):</span>
                <span class="k">pass</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">decay_</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="p">,</span> <span class="n">decay_</span><span class="p">):</span>
                <span class="n">decay</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="p">,</span> <span class="n">decay_</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">decay_</span> <span class="ow">in</span> <span class="n">DECAYS</span><span class="p">:</span>
                <span class="n">decay_</span> <span class="o">=</span> <span class="n">DECAYS</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">decay_</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Unknown learning rate decay method&#39;</span><span class="p">,</span> <span class="n">decay_</span><span class="p">)</span>

            <span class="c1"># Parse step parameters</span>
            <span class="n">step_params</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s1">&#39;first_iter&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
                <span class="s1">&#39;last_iter&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span>
                <span class="o">**</span><span class="n">decay_kwargs</span>
            <span class="p">}</span>
            <span class="k">if</span> <span class="s1">&#39;frequency&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">step_params</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Missing `frequency` key in the decay configuration&#39;</span><span class="p">)</span>

            <span class="c1"># Set defaults for some of the decays</span>
            <span class="k">if</span> <span class="n">decay_</span> <span class="ow">in</span> <span class="n">DECAYS_DEFAULTS</span><span class="p">:</span>
                <span class="n">decay_dict</span> <span class="o">=</span> <span class="n">DECAYS_DEFAULTS</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">decay_</span><span class="p">)</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
                <span class="k">if</span> <span class="n">decay</span> <span class="o">==</span> <span class="n">DECAYS</span><span class="p">[</span><span class="s1">&#39;cos&#39;</span><span class="p">]:</span>
                    <span class="n">decay_dict</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">T_max</span><span class="o">=</span><span class="n">step_params</span><span class="p">[</span><span class="s1">&#39;frequency&#39;</span><span class="p">])</span>
                <span class="n">decay_kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="o">**</span><span class="n">decay_dict</span><span class="p">,</span> <span class="o">**</span><span class="n">decay_kwargs</span><span class="p">}</span>

            <span class="c1"># Remove unnecessary keys from kwargs</span>
            <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;first_iter&#39;</span><span class="p">,</span> <span class="s1">&#39;last_iter&#39;</span><span class="p">,</span> <span class="s1">&#39;frequency&#39;</span><span class="p">]:</span>
                <span class="n">decay_kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

            <span class="c1"># Create decay or store parameters for later usage</span>
            <span class="k">if</span> <span class="n">optimizer</span><span class="p">:</span>
                <span class="n">decay_</span> <span class="o">=</span> <span class="n">decay_</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="o">**</span><span class="n">decay_kwargs</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">decay</span> <span class="o">=</span> <span class="p">(</span><span class="n">decay_</span><span class="p">,</span> <span class="n">decay_kwargs</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">decay</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">decay_</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">decay_step</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">step_params</span><span class="p">)</span></div>


    <span class="c1"># Set pre-initialized model or chain multiple building blocks to create model</span>
<div class="viewcode-block" id="TorchModel.set_model"><a class="viewcode-back" href="../../../../api/batchflow.models.torch.base.html#batchflow.models.torch.base.TorchModel.set_model">[docs]</a>    <span class="k">def</span> <span class="nf">set_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Set the underlying PyTorch model to a supplied one and update training infrastructure. &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">initialize_weights</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_to_device</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">make_infrastructure</span><span class="p">()</span></div>


<div class="viewcode-block" id="TorchModel.build_model"><a class="viewcode-back" href="../../../../api/batchflow.models.torch.base.html#batchflow.models.torch.base.TorchModel.build_model">[docs]</a>    <span class="k">def</span> <span class="nf">build_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Create the instance of PyTorch model by chaining multiple blocks sequentially.</span>
<span class="sd">        After it, create training infrastructure (loss, optimizer, decay).</span>

<span class="sd">        The order is defined by `order` key in the config, which is [`initial_block`, `body`, `head`] by default.</span>
<span class="sd">        Each item in `order` should describe the block name, the config name and method to create. It can be a:</span>
<span class="sd">            - string, then we use it as name, config key and method name</span>
<span class="sd">            - tuple of three elements, which are name, config key and method name or callable</span>
<span class="sd">            - dictionary with three items, which are `block_name`, `config_name` and `method`.</span>

<span class="sd">            The `block_name` is used as the identifier in resulting model, i.e. `model.body`, `model.head`.</span>
<span class="sd">            The `config_name` is used to retrieve block creation parameters from config.</span>
<span class="sd">            The `method` is either a callable or name of the method to get from the current instance.</span>
<span class="sd">            Either method or callable should return an instance of nn.Module and accept block parameters.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">make_placeholder_data</span><span class="p">()</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">inputs</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transfer_to_device</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>

        <span class="n">blocks</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;order&#39;</span><span class="p">):</span>
            <span class="c1"># Get the `block_name`, which is used as the name in the Sequential,</span>
            <span class="c1">#         `config_name`, which is used to retrieve parameters from config,</span>
            <span class="c1">#     and `method`, which is either a callable or name of the method to get from the current instance</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                <span class="n">block_name</span> <span class="o">=</span> <span class="n">config_name</span> <span class="o">=</span> <span class="n">method</span> <span class="o">=</span> <span class="n">item</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">item</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
                <span class="n">block_name</span><span class="p">,</span> <span class="n">config_name</span><span class="p">,</span> <span class="n">method</span> <span class="o">=</span> <span class="n">item</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
                <span class="n">block_name</span> <span class="o">=</span> <span class="n">item</span><span class="p">[</span><span class="s1">&#39;block_name&#39;</span><span class="p">]</span>
                <span class="n">config_name</span> <span class="o">=</span> <span class="n">item</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;config_name&#39;</span><span class="p">,</span> <span class="n">block_name</span><span class="p">)</span>
                <span class="n">method</span> <span class="o">=</span> <span class="n">item</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;method&#39;</span><span class="p">,</span> <span class="n">config_name</span><span class="p">)</span>

            <span class="c1"># Make block, from the `inputs`, transfer it to device</span>
            <span class="c1"># Important: apply to the `inputs` before passing them to the next block, so the shapes/etc are updated</span>
            <span class="n">block</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">make_block</span><span class="p">(</span><span class="n">config_name</span><span class="p">,</span> <span class="n">method</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">block</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">block</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                <span class="n">inputs</span> <span class="o">=</span> <span class="n">block</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
                <span class="n">blocks</span><span class="p">[</span><span class="n">block_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">block</span>

        <span class="c1"># Use the OrderedDict in Sequential to give readable names to stages</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">blocks</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">initialize_weights</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_to_device</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">make_infrastructure</span><span class="p">()</span></div>

<div class="viewcode-block" id="TorchModel.make_block"><a class="viewcode-back" href="../../../../api/batchflow.models.torch.base.html#batchflow.models.torch.base.TorchModel.make_block">[docs]</a>    <span class="k">def</span> <span class="nf">make_block</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">method</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Create the block with `method` by retrieving its parameters from config by `name`. &quot;&quot;&quot;</span>
        <span class="n">config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span>
        <span class="n">block</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">block</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
            <span class="c1"># Already initialized module</span>
            <span class="k">pass</span>

        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">block</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="n">block_params</span> <span class="o">=</span> <span class="p">{</span><span class="o">**</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;common&#39;</span><span class="p">],</span> <span class="o">**</span><span class="n">block</span><span class="p">}</span>

            <span class="k">if</span> <span class="s1">&#39;module&#39;</span> <span class="ow">in</span> <span class="n">block_params</span><span class="p">:</span>
                <span class="c1"># A custom module</span>
                <span class="n">module</span> <span class="o">=</span> <span class="n">block_params</span><span class="p">[</span><span class="s1">&#39;module&#39;</span><span class="p">]</span>

                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
                    <span class="c1"># Already initialized module</span>
                    <span class="n">block</span> <span class="o">=</span> <span class="n">module</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># Initialize module with parameters from config. Add `inputs`, if needed</span>
                    <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="o">**</span><span class="n">block</span><span class="p">,</span> <span class="o">**</span><span class="n">block_params</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;module_kwargs&#39;</span><span class="p">,</span> <span class="p">{})}</span>
                    <span class="k">if</span> <span class="s1">&#39;inputs&#39;</span> <span class="ow">in</span> <span class="n">inspect</span><span class="o">.</span><span class="n">getfullargspec</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="fm">__init__</span><span class="p">)[</span><span class="mi">0</span><span class="p">]:</span>
                        <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;inputs&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">inputs</span>
                    <span class="n">block</span> <span class="o">=</span> <span class="n">module</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># A string to get the module from the instance or callable that returns nn.Module</span>
                <span class="n">method</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">method</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">method</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">method</span>
                <span class="n">block</span> <span class="o">=</span> <span class="n">method</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="o">**</span><span class="n">block_params</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;`</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s1">` must be configured either as nn.Module or dictionary, got </span><span class="si">{</span><span class="n">block_params</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">block</span></div>


    <span class="c1"># Pre-defined building blocks</span>
<div class="viewcode-block" id="TorchModel.get_block_defaults"><a class="viewcode-back" href="../../../../api/batchflow.models.torch.base.html#batchflow.models.torch.base.TorchModel.get_block_defaults">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">get_block_defaults</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Make block parameters from class default config and kwargs. &quot;&quot;&quot;</span>
        <span class="n">class_config</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">default_config</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">class_config</span><span class="p">[</span><span class="s1">&#39;common&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">Config</span><span class="p">(</span><span class="n">class_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">name</span><span class="p">))</span> <span class="o">+</span> <span class="p">(</span><span class="n">kwargs</span> <span class="ow">or</span> <span class="p">{})</span></div>

<div class="viewcode-block" id="TorchModel.block"><a class="viewcode-back" href="../../../../api/batchflow.models.torch.base.html#batchflow.models.torch.base.TorchModel.block">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">block</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Model building block. &quot;&quot;&quot;</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">get_block_defaults</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;layout&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;base_block&#39;</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">ConvBlock</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">return</span> <span class="kc">None</span></div>

<div class="viewcode-block" id="TorchModel.initial_block"><a class="viewcode-back" href="../../../../api/batchflow.models.torch.base.html#batchflow.models.torch.base.TorchModel.initial_block">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">initial_block</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Transform inputs. Usually used for initial preprocessing, e.g. reshaping, downsampling etc.</span>
<span class="sd">        For parameters see :class:`~.torch.layers.ConvBlock`.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.nn.Module or None</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">cls</span><span class="o">.</span><span class="n">block</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;initial_block&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

<div class="viewcode-block" id="TorchModel.body"><a class="viewcode-back" href="../../../../api/batchflow.models.torch.base.html#batchflow.models.torch.base.TorchModel.body">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">body</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Base layers which produce a network embedding.</span>
<span class="sd">        For parameters see :class:`~.torch.layers.ConvBlock`.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.nn.Module or None</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">cls</span><span class="o">.</span><span class="n">block</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;body&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

<div class="viewcode-block" id="TorchModel.head"><a class="viewcode-back" href="../../../../api/batchflow.models.torch.base.html#batchflow.models.torch.base.TorchModel.head">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">head</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Produce predictions. Usually used to make network output compatible with the `targets` tensor.</span>
<span class="sd">        For parameters see :class:`~.torch.layers.ConvBlock`.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.nn.Module or None</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">cls</span><span class="o">.</span><span class="n">block</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;head&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>


    <span class="c1"># Model weights initialization</span>
<div class="viewcode-block" id="TorchModel.initialize_weights"><a class="viewcode-back" href="../../../../api/batchflow.models.torch.base.html#batchflow.models.torch.base.TorchModel.initialize_weights">[docs]</a>    <span class="k">def</span> <span class="nf">initialize_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Initialize model weights with a pre-defined or supplied callable. &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="ow">and</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">init_weights</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">):</span>
            <span class="c1"># Parse model weights initilaization</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">init_weights</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                <span class="c1"># We have only one variant of predefined init function, so we check that init is str for a typo case</span>
                <span class="c1"># The common used non-default weights initialization:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">init_weights</span> <span class="o">=</span> <span class="n">best_practice_resnet_init</span>

            <span class="c1"># Actual weights initialization</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">init_weights</span><span class="p">)</span></div>


    <span class="c1"># Transfer to/from device(s)</span>
<div class="viewcode-block" id="TorchModel.transfer_to_device"><a class="viewcode-back" href="../../../../api/batchflow.models.torch.base.html#batchflow.models.torch.base.TorchModel.transfer_to_device">[docs]</a>    <span class="k">def</span> <span class="nf">transfer_to_device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Transfer (possibly nested) data structure to device and return the same structure. &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="p">(</span><span class="nb">dict</span><span class="p">,</span> <span class="n">Config</span><span class="p">)):</span>
            <span class="k">return</span> <span class="nb">type</span><span class="p">(</span><span class="n">data</span><span class="p">)({</span><span class="n">key</span> <span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">transfer_to_device</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">items</span><span class="p">()})</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">)):</span>
            <span class="k">return</span> <span class="nb">type</span><span class="p">(</span><span class="n">data</span><span class="p">)(</span><span class="bp">self</span><span class="o">.</span><span class="n">transfer_to_device</span><span class="p">(</span><span class="n">item</span><span class="p">)</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">data</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">data</span><span class="o">.</span><span class="n">dtype</span> <span class="o">!=</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">:</span>
                <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">data</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">data</span>

        <span class="k">if</span> <span class="n">CUPY_AVAILABLE</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">cp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">data</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">id</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">index</span><span class="p">:</span>
                <span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">dlpack</span><span class="o">.</span><span class="n">from_dlpack</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">toDlpack</span><span class="p">())</span>
                <span class="k">return</span> <span class="n">data</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;cupy arrays should reside on the same GPU, as model itself: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="s1">.&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">data</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;Passed data should either be a `np.ndarray`, `torch.Tensor`, `cupy.ndarray`, &#39;</span>
                        <span class="sa">f</span><span class="s1">&#39;or a container of them, got</span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="si">}</span><span class="s1">.&#39;</span><span class="p">)</span></div>

<div class="viewcode-block" id="TorchModel.transfer_from_device"><a class="viewcode-back" href="../../../../api/batchflow.models.torch.base.html#batchflow.models.torch.base.TorchModel.transfer_from_device">[docs]</a>    <span class="k">def</span> <span class="nf">transfer_from_device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Transfer (possibly nested) data structure from device and return the same structure. &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="p">(</span><span class="nb">dict</span><span class="p">,</span> <span class="n">Config</span><span class="p">)):</span>
            <span class="k">return</span> <span class="nb">type</span><span class="p">(</span><span class="n">data</span><span class="p">)({</span><span class="n">key</span> <span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">transfer_from_device</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">items</span><span class="p">()})</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">)):</span>
            <span class="k">return</span> <span class="nb">type</span><span class="p">(</span><span class="n">data</span><span class="p">)(</span><span class="bp">self</span><span class="o">.</span><span class="n">transfer_from_device</span><span class="p">(</span><span class="n">item</span><span class="p">)</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">data</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">Variable</span><span class="p">)):</span>
            <span class="n">cpu_tensor</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">amp</span> <span class="ow">and</span> <span class="n">cpu_tensor</span><span class="o">.</span><span class="n">dtype</span> <span class="o">!=</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">:</span>
                <span class="n">cpu_tensor</span> <span class="o">=</span> <span class="n">cpu_tensor</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">cpu_tensor</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">)):</span>
            <span class="k">return</span> <span class="n">data</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;Passed data should either be a `np.ndarray`, `torch.Tensor`&#39;</span>
                        <span class="sa">f</span><span class="s1">&#39; or a container of them, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="si">}</span><span class="s1">.&#39;</span><span class="p">)</span></div>

<div class="viewcode-block" id="TorchModel.model_to_device"><a class="viewcode-back" href="../../../../api/batchflow.models.torch.base.html#batchflow.models.torch.base.TorchModel.model_to_device">[docs]</a>    <span class="k">def</span> <span class="nf">model_to_device</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Put model on device(s). If needed, apply DataParallel wrapper. &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">devices</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">DataParallel</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">devices</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span></div>


    <span class="c1"># Apply model to train/predict on given data</span>
<div class="viewcode-block" id="TorchModel.train"><a class="viewcode-back" href="../../../../api/batchflow.models.torch.base.html#batchflow.models.torch.base.TorchModel.train">[docs]</a>    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">lock</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">profile</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
              <span class="n">sync_frequency</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">microbatch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">microbatch_drop_last</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
              <span class="n">sam_rho</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">sam_individual_norm</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Train the model with the data provided</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        inputs : np.ndarray or sequence of them</span>
<span class="sd">            Model inputs. If there is a single input, then it is passed to model directly; otherwise, we pass a list.</span>
<span class="sd">            If the microbatching is used, individual elements are split along the first axis.</span>
<span class="sd">        targets : np.ndarray or sequence of them</span>
<span class="sd">            Model targets to calculate loss with.</span>
<span class="sd">            If there is a single target, then it is passed to loss computation directly; otherwise, we pass a list.</span>
<span class="sd">            If the microbatching is used, individual elements are split along the first axis.</span>
<span class="sd">        outputs : str or sequence of them</span>
<span class="sd">            Desired outputs of the method.</span>
<span class="sd">            Each string defines a tensor to get and should be one of pre-defined or set in `outputs` key in the config.</span>
<span class="sd">            Pre-defined tensors are `predictions`, `loss`, and `predictions_{i}` for multi-output models.</span>
<span class="sd">        lock : bool</span>
<span class="sd">            If True, then model, loss and gradient update operations are locked, thus allowing for multithreading.</span>
<span class="sd">        sync_frequency : int, bool or None</span>
<span class="sd">            If int, then how often to apply accumulated gradients to the weights.</span>
<span class="sd">            If True, then value from config is used.</span>
<span class="sd">            Default value is 1, which means to apply gradients after each batch of data.</span>
<span class="sd">            If False or None, then gradients are applied after each batch of data.</span>
<span class="sd">        microbatch_size : int, bool or None</span>
<span class="sd">            If int, then size of chunks to split every batch into. Allows to process given data sequentially,</span>
<span class="sd">            accumulating gradients from microbatches and applying them once in the end.</span>
<span class="sd">            If None, then value from config is used (default value is not to use microbatching).</span>
<span class="sd">            If False, then microbatching is not used.</span>
<span class="sd">        microbatch_drop_last : bool</span>
<span class="sd">            Whether to drop microbatches, that are smaller than the microbatch size. Default is True.</span>
<span class="sd">        sam_rho : float</span>
<span class="sd">            Foret P. et al. &quot;`Sharpness-Aware Minimization for Efficiently Improving Generalization</span>
<span class="sd">            &lt;https://arxiv.org/abs/2010.01412&gt;`_&quot;.</span>
<span class="sd">            If evaluates to False, then SAM is not used.</span>
<span class="sd">            If float, then controls the size of neighborhood (check the paper for details).</span>
<span class="sd">        sam_individual_norm : bool</span>
<span class="sd">            If True, then each gradient is scaled according to its own L2 norm.</span>
<span class="sd">            If False, then one common gradient norm is computed and used as a scaler for all gradients.</span>
<span class="sd">        profile : bool</span>
<span class="sd">            Whether to collect stats of model training timings.</span>
<span class="sd">            If True, then stats can be accessed via `profile_info` attribute or :meth:`.show_profile_info` method.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Calculated values of requested tensors from `outputs` in the same order.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        .. code-block:: python</span>

<span class="sd">            model.train(B(&#39;images&#39;), B(&#39;labels&#39;), fetches=&#39;loss&#39;)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Lock the entire method; release in any case</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">lock</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model_lock</span><span class="o">.</span><span class="n">acquire</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">last_train_info</span> <span class="o">=</span> <span class="p">{}</span>

            <span class="c1"># Parse inputs and targets: always a list</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">))</span> <span class="k">else</span> <span class="p">[</span><span class="n">inputs</span><span class="p">]</span>
            <span class="n">targets</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">targets</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">targets</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">))</span> <span class="k">else</span> <span class="p">[</span><span class="n">targets</span><span class="p">]</span>

            <span class="c1"># Parse outputs: always a list</span>
            <span class="n">single_output</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">outputs</span><span class="p">]</span> <span class="k">if</span> <span class="n">single_output</span> <span class="k">else</span> <span class="p">(</span><span class="n">outputs</span> <span class="ow">or</span> <span class="p">[])</span>

            <span class="c1"># Parse train parameters</span>
            <span class="k">if</span> <span class="n">sync_frequency</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                <span class="n">sync_frequency</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sync_frequency</span>
            <span class="k">elif</span> <span class="n">sync_frequency</span> <span class="ow">is</span> <span class="kc">False</span> <span class="ow">or</span> <span class="n">sync_frequency</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">sync_frequency</span> <span class="o">=</span> <span class="mi">1</span>

            <span class="c1"># Prepare parameters for SAM</span>
            <span class="k">if</span> <span class="n">sam_rho</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">sam_rho</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sam_rho</span>
            <span class="k">if</span> <span class="n">sam_individual_norm</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">sam_individual_norm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sam_individual_norm</span>

            <span class="c1"># Split the data into `microbatch_size` size chunks</span>
            <span class="p">(</span><span class="n">chunked_inputs</span><span class="p">,</span> <span class="n">chunked_targets</span><span class="p">,</span>
             <span class="n">batch_size</span><span class="p">,</span> <span class="n">microbatch_size</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">split_into_microbatches</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span>
                                                                         <span class="n">microbatch_size</span><span class="p">,</span> <span class="n">microbatch_drop_last</span><span class="p">)</span>

            <span class="n">steps</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">chunked_inputs</span><span class="p">)</span>
            <span class="n">inputs_shapes</span> <span class="o">=</span> <span class="p">[</span><span class="n">get_shape</span><span class="p">(</span><span class="n">item</span><span class="p">)</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">chunked_inputs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span>
            <span class="n">targets_shapes</span> <span class="o">=</span> <span class="p">[</span><span class="n">get_shape</span><span class="p">(</span><span class="n">item</span><span class="p">)</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">chunked_targets</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">last_train_info</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s1">&#39;inputs_shapes&#39;</span><span class="p">:</span> <span class="n">inputs_shapes</span><span class="p">,</span>
                                         <span class="s1">&#39;targets_shapes&#39;</span><span class="p">:</span> <span class="n">targets_shapes</span><span class="p">})</span>

            <span class="c1"># Create PyTorch model if it is yet to be initialized, based on the actual inputs</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># Update config with shapes</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">inputs_shapes</span> <span class="o">=</span> <span class="n">inputs_shapes</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">targets_shapes</span> <span class="o">=</span> <span class="n">targets_shapes</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">classes</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">targets_shapes</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">classes</span> <span class="o">=</span> <span class="p">[</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">shape</span> <span class="ow">in</span> <span class="n">targets_shapes</span><span class="p">]</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">update_config</span><span class="p">()</span>

                <span class="c1"># Can use the first two items to build model: no need for the whole tensor</span>
                <span class="n">build_inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">item</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">chunked_inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">build_model</span><span class="p">(</span><span class="n">build_inputs</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

            <span class="c1"># Set up the profiling, if needed</span>
            <span class="n">profile</span> <span class="o">=</span> <span class="n">profile</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">profile</span>
            <span class="k">if</span> <span class="n">profile</span><span class="p">:</span>
                <span class="n">profiler</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">profile</span><span class="p">(</span><span class="n">use_cuda</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span><span class="p">)</span>
                <span class="n">profiler</span><span class="o">.</span><span class="fm">__enter__</span><span class="p">()</span>

            <span class="c1"># Train on each of the microbatches</span>
            <span class="n">chunked_outputs</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">chunk_inputs</span><span class="p">,</span> <span class="n">chunk_targets</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">chunked_inputs</span><span class="p">,</span> <span class="n">chunked_targets</span><span class="p">):</span>
                <span class="c1"># Compute forward and backward passes of the model, apply gradients, evaluate requested outputs</span>
                <span class="n">chunk_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">chunk_inputs</span><span class="p">,</span> <span class="n">targets</span><span class="o">=</span><span class="n">chunk_targets</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">[:],</span>
                                            <span class="n">sync_frequency</span><span class="o">=</span><span class="n">sync_frequency</span><span class="o">*</span><span class="n">steps</span><span class="p">,</span>
                                            <span class="n">sam_rho</span><span class="o">=</span><span class="n">sam_rho</span><span class="p">,</span> <span class="n">sam_individual_norm</span><span class="o">=</span><span class="n">sam_individual_norm</span><span class="p">)</span>
                <span class="n">chunked_outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">chunk_outputs</span><span class="p">)</span>

            <span class="c1"># Exit the profiling</span>
            <span class="k">if</span> <span class="n">profile</span><span class="p">:</span>
                <span class="n">profiler</span><span class="o">.</span><span class="fm">__exit__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">profilers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">profiler</span><span class="p">)</span>

            <span class="c1"># Call the callbacks</span>
            <span class="k">for</span> <span class="n">callback</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span>
                <span class="n">callback</span><span class="o">.</span><span class="n">on_iter_end</span><span class="p">()</span>

            <span class="c1"># Aggregate the outputs from microbatches</span>
            <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">aggregate_microbatches</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">chunked_outputs</span><span class="p">,</span> <span class="n">single_output</span><span class="p">)</span>

            <span class="c1"># Store the average value of loss over microbatches</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">loss_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_loss_list</span><span class="p">[</span><span class="o">-</span><span class="n">steps</span><span class="p">:]))</span>

            <span class="c1"># Store info about current train iteration</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">last_train_info</span><span class="o">.</span><span class="n">update</span><span class="p">({</span>
                <span class="s1">&#39;amp&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">amp</span><span class="p">,</span>
                <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="n">batch_size</span><span class="p">,</span>
                <span class="s1">&#39;microbatch_size&#39;</span><span class="p">:</span> <span class="n">microbatch_size</span><span class="p">,</span>
                <span class="s1">&#39;sync_frequency&#39;</span><span class="p">:</span> <span class="n">sync_frequency</span><span class="p">,</span>
                <span class="s1">&#39;steps&#39;</span><span class="p">:</span> <span class="n">steps</span><span class="p">,</span>
                <span class="s1">&#39;sam&#39;</span><span class="p">:</span> <span class="nb">bool</span><span class="p">(</span><span class="n">sam_rho</span><span class="p">),</span> <span class="s1">&#39;sam_rho&#39;</span><span class="p">:</span> <span class="n">sam_rho</span><span class="p">,</span>
                <span class="s1">&#39;sam_individual_norm&#39;</span><span class="p">:</span> <span class="n">sam_individual_norm</span><span class="p">,</span>
                <span class="s1">&#39;outputs&#39;</span><span class="p">:</span> <span class="n">outputs</span><span class="p">,</span>
            <span class="p">})</span>

        <span class="k">finally</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">lock</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model_lock</span><span class="o">.</span><span class="n">release</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">result</span></div>

    <span class="k">def</span> <span class="nf">_train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">sync_frequency</span><span class="p">,</span> <span class="n">sam_rho</span><span class="p">,</span> <span class="n">sam_individual_norm</span><span class="p">):</span>
        <span class="c1"># Parse inputs</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">inputs</span>
        <span class="n">targets</span> <span class="o">=</span> <span class="n">targets</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">targets</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">targets</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transfer_to_device</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">targets</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transfer_to_device</span><span class="p">(</span><span class="n">targets</span><span class="p">)</span>

        <span class="c1"># Convert layer ids into LayerHooks</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prepare_outputs</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>

        <span class="c1"># Compute predictions; store shapes for introspection</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">amp</span><span class="o">.</span><span class="n">autocast</span><span class="p">(</span><span class="n">enabled</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">amp</span><span class="p">):</span>
            <span class="n">predictions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>

        <span class="c1"># SAM: store grads from previous microbatches</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">iteration</span> <span class="o">&gt;=</span> <span class="mi">1</span> <span class="ow">and</span> <span class="nb">bool</span><span class="p">(</span><span class="n">sam_rho</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_train_sam_store_gradients</span><span class="p">()</span>

        <span class="c1"># Compute loss and gradients; store loss value for every microbatch</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">amp</span><span class="o">.</span><span class="n">autocast</span><span class="p">(</span><span class="n">enabled</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">amp</span><span class="p">):</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
            <span class="n">loss_</span> <span class="o">=</span> <span class="n">loss</span> <span class="o">/</span> <span class="n">sync_frequency</span>
        <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scaler</span><span class="o">.</span><span class="n">scale</span><span class="p">(</span><span class="n">loss_</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">amp</span> <span class="k">else</span> <span class="n">loss_</span><span class="p">)</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_loss_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">transfer_from_device</span><span class="p">(</span><span class="n">loss</span><span class="p">))</span>

        <span class="c1"># SAM: use obtained grads to move to the local maxima</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">iteration</span> <span class="o">&gt;=</span> <span class="mi">1</span> <span class="ow">and</span> <span class="nb">bool</span><span class="p">(</span><span class="n">sam_rho</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_train_sam_update_gradients</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="o">=</span><span class="n">targets</span><span class="p">,</span> <span class="n">sync_frequency</span><span class="o">=</span><span class="n">sync_frequency</span><span class="p">,</span>
                                             <span class="n">sam_rho</span><span class="o">=</span><span class="n">sam_rho</span><span class="p">,</span> <span class="n">sam_individual_norm</span><span class="o">=</span><span class="n">sam_individual_norm</span><span class="p">)</span>

        <span class="c1"># Whether to update weights or keep accumulating</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">sync_counter</span> <span class="o">==</span> <span class="n">sync_frequency</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># Store learning rate: we do it before decay, so it is actual LR used on this iteration</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">lr_list</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">group</span><span class="p">[</span><span class="s1">&#39;lr&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">group</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">])</span>

            <span class="c1"># Update weights and remove grads</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">amp</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">scaler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">scaler</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="c1"># Optimization over default `zero_grad`; can be removed after PyTorch &gt;= 1.8</span>
            <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
                <span class="n">p</span><span class="o">.</span><span class="n">grad</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">iteration</span> <span class="o">+=</span> <span class="mi">1</span>

            <span class="c1"># Apply decay to learning rate, if needed</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">decay</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">decay</span><span class="p">,</span> <span class="n">decay_step</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">decay</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">decay_step</span><span class="p">):</span>
                    <span class="n">step_cond</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">iteration</span> <span class="o">-</span> <span class="n">decay_step</span><span class="p">[</span><span class="s1">&#39;first_iter&#39;</span><span class="p">])</span> <span class="o">%</span> <span class="n">decay_step</span><span class="p">[</span><span class="s1">&#39;frequency&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span>
                    <span class="n">range_cond</span> <span class="o">=</span> <span class="n">decay_step</span><span class="p">[</span><span class="s1">&#39;first_iter&#39;</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">iteration</span> <span class="o">&lt;=</span> <span class="n">decay_step</span><span class="p">[</span><span class="s1">&#39;last_iter&#39;</span><span class="p">]</span>
                    <span class="k">if</span> <span class="n">step_cond</span> <span class="ow">and</span> <span class="n">range_cond</span><span class="p">:</span>
                        <span class="n">decay</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">decay_iters</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">iteration</span><span class="p">)</span>

            <span class="c1"># Update counters</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sync_counter</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">syncs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sync_counter</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">syncs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

        <span class="c1"># Make all possible outputs</span>
        <span class="n">additional_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_outputs</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">)</span>
        <span class="n">output_container</span> <span class="o">=</span> <span class="p">{</span>
            <span class="o">**</span><span class="n">additional_outputs</span><span class="p">,</span>
            <span class="s1">&#39;predictions&#39;</span><span class="p">:</span> <span class="n">predictions</span><span class="p">,</span>
            <span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="p">,</span>
        <span class="p">}</span>

        <span class="c1"># Log inner info</span>
        <span class="n">predictions_</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">))</span> <span class="k">else</span> <span class="p">[</span><span class="n">predictions</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">last_train_info</span><span class="p">[</span><span class="s1">&#39;predictions_shapes&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">get_shape</span><span class="p">(</span><span class="n">item</span><span class="p">)</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">predictions_</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">last_train_info</span><span class="p">[</span><span class="s1">&#39;available_outputs&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">output_container</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

        <span class="c1"># Retrieve requested outputs</span>
        <span class="n">requested_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">extract_outputs</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">output_container</span><span class="p">)</span>

        <span class="c1"># Transfer only the requested outputs to CPU</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">transfer_from_device</span><span class="p">(</span><span class="n">requested_outputs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_train_sam_store_gradients</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Store gradients from previous microbatches. &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">state</span><span class="p">[</span><span class="n">p</span><span class="p">][</span><span class="s1">&#39;previous_grad&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
                <span class="n">p</span><span class="o">.</span><span class="n">grad</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">_train_sam_update_gradients</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">sync_frequency</span><span class="p">,</span> <span class="n">sam_rho</span><span class="p">,</span> <span class="n">sam_individual_norm</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Update gradients to move to the local maxima. &quot;&quot;&quot;</span>
        <span class="c1"># Fetch gradients</span>
        <span class="n">grads</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">params_with_grads</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">grads</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>
                <span class="n">params_with_grads</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
                <span class="n">p</span><span class="o">.</span><span class="n">grad</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># Move to the local maxima</span>
        <span class="k">if</span> <span class="n">sam_individual_norm</span><span class="p">:</span>
            <span class="n">epsilons</span> <span class="o">=</span> <span class="p">[</span><span class="n">grad</span> <span class="o">*</span> <span class="n">sam_rho</span> <span class="o">/</span> <span class="p">(</span><span class="n">grad</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">))</span> <span class="k">for</span> <span class="n">grad</span> <span class="ow">in</span> <span class="n">grads</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">grad_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">g</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">g</span> <span class="ow">in</span> <span class="n">grads</span><span class="p">])</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
            <span class="n">epsilons</span> <span class="o">=</span> <span class="p">[</span><span class="n">eps</span> <span class="o">*</span> <span class="n">sam_rho</span> <span class="o">/</span> <span class="n">grad_norm</span> <span class="k">for</span> <span class="n">eps</span> <span class="ow">in</span> <span class="n">grads</span><span class="p">]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">amp</span><span class="p">:</span>
            <span class="n">scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scaler</span><span class="o">.</span><span class="n">get_scale</span><span class="p">()</span>
            <span class="n">epsilons</span> <span class="o">=</span> <span class="p">[</span><span class="n">eps</span> <span class="o">/</span> <span class="n">scale</span> <span class="k">for</span> <span class="n">eps</span> <span class="ow">in</span> <span class="n">epsilons</span><span class="p">]</span>
        <span class="n">params_with_grads</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span> <span class="o">+</span> <span class="n">eps</span> <span class="k">for</span> <span class="n">p</span><span class="p">,</span> <span class="n">eps</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">params_with_grads</span><span class="p">,</span> <span class="n">epsilons</span><span class="p">)]</span>

        <span class="c1"># Compute new gradients: direction to move to minimize the local maxima</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">amp</span><span class="o">.</span><span class="n">autocast</span><span class="p">(</span><span class="n">enabled</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">amp</span><span class="p">):</span>
            <span class="n">predictions_inner</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
            <span class="n">loss_inner</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">predictions_inner</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span> <span class="o">/</span> <span class="n">sync_frequency</span>
        <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scaler</span><span class="o">.</span><span class="n">scale</span><span class="p">(</span><span class="n">loss_inner</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">amp</span> <span class="k">else</span> <span class="n">loss_inner</span><span class="p">)</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

        <span class="c1"># Cancel the previous update to model parameters, add stored gradients from previous microbatches</span>
        <span class="n">params_with_grads</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span> <span class="o">-</span> <span class="n">eps</span> <span class="k">for</span> <span class="n">p</span><span class="p">,</span> <span class="n">eps</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">params_with_grads</span><span class="p">,</span> <span class="n">epsilons</span><span class="p">)]</span>

        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
            <span class="n">previous_grad</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">state</span><span class="p">[</span><span class="n">p</span><span class="p">]</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;previous_grad&#39;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">previous_grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">add_</span><span class="p">(</span><span class="n">previous_grad</span><span class="p">)</span>


<div class="viewcode-block" id="TorchModel.predict"><a class="viewcode-back" href="../../../../api/batchflow.models.torch.base.html#batchflow.models.torch.base.TorchModel.predict">[docs]</a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">lock</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">microbatch_size</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Get predictions on the data provided.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        inputs : np.ndarray or sequence of them</span>
<span class="sd">            Model inputs. Passed directly to model.</span>
<span class="sd">        targets : np.ndarray or sequence of them</span>
<span class="sd">            Optional model targets to calculate loss with. Passed directly to model.</span>
<span class="sd">        outputs : str or sequence of them</span>
<span class="sd">            Desired outputs of the method.</span>
<span class="sd">            Each string defines a tensor to get and should be one of:</span>
<span class="sd">                - pre-defined tensors, which are `predictions`, `loss`, and `predictions_{i}` for multi-output models.</span>
<span class="sd">                - values described in the `outputs` key in the config</span>
<span class="sd">                - layer id, which describes how to access the layer through a series of `getattr` and `getitem` calls.</span>
<span class="sd">                Allows to get intermediate activations of a neural network.</span>
<span class="sd">        lock : bool</span>
<span class="sd">            If True, then model and loss computation operations are locked, thus allowing for multithreading.</span>
<span class="sd">        microbatch_size : int, bool or None</span>
<span class="sd">            If int, then size of chunks to split every batch into. Allows to process given data sequentially.</span>
<span class="sd">            If None, then value from config is used (default value is not to use microbatching).</span>
<span class="sd">            If False, then microbatching is not used.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Calculated values of tensors in `outputs` in the same order.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        Layer ids allow to get intermediate activations. If the model has `batchflow_model.model.head[0]` layer,</span>
<span class="sd">        you can access it with::</span>

<span class="sd">        &gt;&gt;&gt; batchflow_model.predict(inputs=B.images, outputs=&#39;model.head[0]&#39;)</span>

<span class="sd">        String keys for `getitem` calls are also allowed::</span>

<span class="sd">        &gt;&gt;&gt; batchflow_model.predict(inputs=B.images, outputs=&#39;model.body.encoder[&quot;block-0&quot;]&#39;)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Acquire lock; release in any case</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">lock</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model_lock</span><span class="o">.</span><span class="n">acquire</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">last_predict_info</span> <span class="o">=</span> <span class="p">{}</span>

            <span class="c1"># Parse inputs and targets: always a list</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">))</span> <span class="k">else</span> <span class="p">[</span><span class="n">inputs</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">targets</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">targets</span> <span class="o">=</span> <span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">targets</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">targets</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">))</span> <span class="k">else</span> <span class="p">[</span><span class="n">targets</span><span class="p">])</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">targets</span> <span class="o">=</span> <span class="p">[]</span>

            <span class="c1"># Parse outputs: always a list</span>
            <span class="n">single_output</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">outputs</span><span class="p">]</span> <span class="k">if</span> <span class="n">single_output</span> <span class="k">else</span> <span class="p">(</span><span class="n">outputs</span> <span class="ow">or</span> <span class="p">[])</span>

            <span class="c1"># Raise error early</span>
            <span class="k">if</span> <span class="s1">&#39;loss&#39;</span> <span class="ow">in</span> <span class="n">outputs</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">targets</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;`targets` should be provided to fetch `loss`!&#39;</span><span class="p">)</span>

            <span class="c1"># Split the data into `microbatch` size chunks</span>
            <span class="p">(</span><span class="n">chunked_inputs</span><span class="p">,</span> <span class="n">chunked_targets</span><span class="p">,</span>
             <span class="n">batch_size</span><span class="p">,</span> <span class="n">microbatch_size</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">split_into_microbatches</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span>
                                                                         <span class="n">microbatch_size</span><span class="p">,</span> <span class="n">drop_last</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

            <span class="n">steps</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">chunked_inputs</span><span class="p">)</span>
            <span class="n">inputs_shapes</span> <span class="o">=</span> <span class="p">[</span><span class="n">get_shape</span><span class="p">(</span><span class="n">item</span><span class="p">)</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">chunked_inputs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span>
            <span class="n">targets_shapes</span> <span class="o">=</span> <span class="p">[</span><span class="n">get_shape</span><span class="p">(</span><span class="n">item</span><span class="p">)</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">chunked_targets</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">last_predict_info</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s1">&#39;inputs_shapes&#39;</span><span class="p">:</span> <span class="n">inputs_shapes</span><span class="p">,</span>
                                           <span class="s1">&#39;targets_shapes&#39;</span><span class="p">:</span> <span class="n">targets_shapes</span><span class="p">})</span>

            <span class="c1"># Evaluate each microbatch separately</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

            <span class="n">chunked_outputs</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">chunk_inputs</span><span class="p">,</span> <span class="n">chunk_targets</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">chunked_inputs</span><span class="p">,</span> <span class="n">chunked_targets</span><span class="p">):</span>
                <span class="c1"># Evaluate requested outputs</span>
                <span class="n">chunk_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_predict</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">chunk_inputs</span><span class="p">,</span> <span class="n">targets</span><span class="o">=</span><span class="n">chunk_targets</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">[:])</span>
                <span class="n">chunked_outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">chunk_outputs</span><span class="p">)</span>

            <span class="c1"># Aggregate the outputs from microbatches</span>
            <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">aggregate_microbatches</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">chunked_outputs</span><span class="p">,</span> <span class="n">single_output</span><span class="p">)</span>

            <span class="c1"># Store info about current predict iteration</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">last_predict_info</span><span class="o">.</span><span class="n">update</span><span class="p">({</span>
                <span class="s1">&#39;amp&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">amp</span><span class="p">,</span>
                <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="n">batch_size</span><span class="p">,</span>
                <span class="s1">&#39;microbatch_size&#39;</span><span class="p">:</span> <span class="n">microbatch_size</span><span class="p">,</span>
                <span class="s1">&#39;steps&#39;</span><span class="p">:</span> <span class="n">steps</span><span class="p">,</span>
                <span class="s1">&#39;outputs&#39;</span><span class="p">:</span> <span class="n">outputs</span><span class="p">,</span>
            <span class="p">})</span>

        <span class="k">finally</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">lock</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model_lock</span><span class="o">.</span><span class="n">release</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">result</span></div>

    <span class="k">def</span> <span class="nf">_predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">outputs</span><span class="p">):</span>
        <span class="c1"># Parse inputs</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">inputs</span>
        <span class="n">targets</span> <span class="o">=</span> <span class="n">targets</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">targets</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">targets</span>

        <span class="c1"># Convert layer ids into LayerHooks</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prepare_outputs</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>

        <span class="n">output_container</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">(),</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">amp</span><span class="o">.</span><span class="n">autocast</span><span class="p">(</span><span class="n">enabled</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">amp</span><span class="p">):</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transfer_to_device</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
            <span class="n">predictions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>

            <span class="n">output_container</span><span class="p">[</span><span class="s1">&#39;predictions&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">predictions</span>

            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">targets</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">targets</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transfer_to_device</span><span class="p">(</span><span class="n">targets</span><span class="p">)</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
                <span class="n">output_container</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">loss</span>

        <span class="c1"># Make all possible outputs</span>
        <span class="n">additional_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_outputs</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">)</span>
        <span class="n">output_container</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">additional_outputs</span><span class="p">)</span>

        <span class="c1"># Log inner info</span>
        <span class="n">predictions_</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">))</span> <span class="k">else</span> <span class="p">[</span><span class="n">predictions</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">last_train_info</span><span class="p">[</span><span class="s1">&#39;predictions_shapes&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">get_shape</span><span class="p">(</span><span class="n">item</span><span class="p">)</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">predictions_</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">last_predict_info</span><span class="p">[</span><span class="s1">&#39;available_outputs&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">output_container</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

        <span class="c1"># Retrieve requested outputs</span>
        <span class="n">requested_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">extract_outputs</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">output_container</span><span class="p">)</span>

        <span class="c1"># Transfer only the requested outputs to CPU</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">transfer_from_device</span><span class="p">(</span><span class="n">requested_outputs</span><span class="p">)</span>


    <span class="c1"># Common utilities for train and predict</span>
<div class="viewcode-block" id="TorchModel.split_into_microbatches"><a class="viewcode-back" href="../../../../api/batchflow.models.torch.base.html#batchflow.models.torch.base.TorchModel.split_into_microbatches">[docs]</a>    <span class="k">def</span> <span class="nf">split_into_microbatches</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">microbatch_size</span><span class="p">,</span> <span class="n">drop_last</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Split inputs and targets into microbatch-sized chunks. &quot;&quot;&quot;</span>
        <span class="c1"># Parse microbatch size</span>
        <span class="k">if</span> <span class="n">microbatch_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">microbatch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">microbatch_size</span>

        <span class="c1"># Compute batch_size and make sure it is the same for all inputs and targets</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">item</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">inputs</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">item</span><span class="p">)</span> <span class="o">!=</span> <span class="n">batch_size</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;All of `inputs` should have the same batch_size, as the first one!&#39;</span>
                                    <span class="sa">f</span><span class="s1">&#39;Input at position `</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">` has batch_size </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">item</span><span class="p">)</span><span class="si">}</span><span class="s1">!=</span><span class="si">{</span><span class="n">batch_size</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">item</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">targets</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">item</span><span class="p">)</span> <span class="o">!=</span> <span class="n">batch_size</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;All of `targets` should have the same batch_size, as the first of `inputs`!&#39;</span>
                                    <span class="sa">f</span><span class="s1">&#39;Target at position `</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">` has batch_size </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">item</span><span class="p">)</span><span class="si">}</span><span class="s1">!=</span><span class="si">{</span><span class="n">batch_size</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

        <span class="c1"># Split data into microbatches, if needed</span>
        <span class="k">if</span> <span class="n">microbatch_size</span><span class="p">:</span>
            <span class="n">chunked_inputs</span> <span class="o">=</span> <span class="p">[[</span><span class="n">item</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">microbatch_size</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">inputs</span><span class="p">]</span>
                                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">microbatch_size</span><span class="p">)]</span>
            <span class="n">chunked_targets</span> <span class="o">=</span> <span class="p">[[</span><span class="n">item</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">microbatch_size</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">targets</span><span class="p">]</span>
                                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">microbatch_size</span><span class="p">)]</span>

            <span class="k">if</span> <span class="n">drop_last</span> <span class="ow">and</span> <span class="n">batch_size</span> <span class="o">%</span> <span class="n">microbatch_size</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">chunked_inputs</span> <span class="o">=</span> <span class="n">chunked_inputs</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
                <span class="n">chunked_targets</span> <span class="o">=</span> <span class="n">chunked_targets</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">chunked_inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">inputs</span><span class="p">]</span>
            <span class="n">chunked_targets</span> <span class="o">=</span> <span class="p">[</span><span class="n">targets</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">chunked_inputs</span><span class="p">,</span> <span class="n">chunked_targets</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">microbatch_size</span></div>

<div class="viewcode-block" id="TorchModel.aggregate_microbatches"><a class="viewcode-back" href="../../../../api/batchflow.models.torch.base.html#batchflow.models.torch.base.TorchModel.aggregate_microbatches">[docs]</a>    <span class="k">def</span> <span class="nf">aggregate_microbatches</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">chunked_outputs</span><span class="p">,</span> <span class="n">single_output</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Aggregate outputs from microbatches into outputs for the whole batch.</span>
<span class="sd">        Scalar values are aggregated by `mean`, array values are concatenated along the first (batch) axis.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">result</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">outputs</span><span class="p">):</span>
            <span class="c1"># All tensors for current `output_name`</span>
            <span class="n">chunked_output</span> <span class="o">=</span> <span class="p">[</span><span class="n">chunk_outputs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">chunk_outputs</span> <span class="ow">in</span> <span class="n">chunked_outputs</span><span class="p">]</span>

            <span class="k">if</span> <span class="n">chunked_output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">size</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">chunked_output</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">chunked_output</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">single_output</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">result</span></div>


<div class="viewcode-block" id="TorchModel.compute_outputs"><a class="viewcode-back" href="../../../../api/batchflow.models.torch.base.html#batchflow.models.torch.base.TorchModel.compute_outputs">[docs]</a>    <span class="k">def</span> <span class="nf">compute_outputs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">predictions</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Produce additional outputs, defined in the config, from `predictions`.</span>
<span class="sd">        Also adds a number of aliases to predicted tensors.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">))</span> <span class="k">else</span> <span class="p">[</span><span class="n">predictions</span><span class="p">]</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">operations</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Not enough predictions (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span><span class="si">}</span><span class="s1">) to apply </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">operations</span><span class="p">)</span><span class="si">}</span><span class="s1"> operations.&#39;</span>
                             <span class="s1">&#39; Revise the `output` config key!&#39;</span><span class="p">)</span>

        <span class="c1"># Add default aliases for each predicted tensor</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="p">{</span><span class="sa">f</span><span class="s1">&#39;predictions_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">:</span> <span class="n">tensor</span>  <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">tensor</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">predictions</span><span class="p">)}</span>

        <span class="c1"># Iterate over tensors in predictions and the corresponding output operations</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="p">(</span><span class="n">output_prefix</span><span class="p">,</span> <span class="n">output_operations</span><span class="p">))</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">operations</span><span class="o">.</span><span class="n">items</span><span class="p">())):</span>
            <span class="c1"># Save the tensor itself under the `output_prefix` name</span>
            <span class="k">if</span> <span class="n">output_prefix</span><span class="p">:</span>
                <span class="n">outputs</span><span class="p">[</span><span class="n">output_prefix</span><span class="p">]</span> <span class="o">=</span> <span class="n">tensor</span>

            <span class="n">output_prefix</span> <span class="o">=</span> <span class="n">output_prefix</span> <span class="o">+</span> <span class="s1">&#39;_&#39;</span> <span class="k">if</span> <span class="n">output_prefix</span> <span class="k">else</span> <span class="s1">&#39;&#39;</span>

            <span class="c1"># For each operation, add multiple aliases</span>
            <span class="k">if</span> <span class="n">output_operations</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">operation</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">output_operations</span><span class="p">):</span>
                    <span class="n">output_tensor</span><span class="p">,</span> <span class="n">operation_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">apply_output_operation</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">operation</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">operation_name</span><span class="p">:</span>
                        <span class="n">outputs</span><span class="p">[</span><span class="n">output_prefix</span> <span class="o">+</span> <span class="n">operation_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">output_tensor</span> <span class="c1"># i.e. `first_sigmoid`, `sigmoid`</span>

                    <span class="n">outputs</span><span class="o">.</span><span class="n">update</span><span class="p">({</span>
                        <span class="n">output_prefix</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">j</span><span class="p">)</span> <span class="p">:</span> <span class="n">output_tensor</span><span class="p">,</span> <span class="c1"># i.e. `first_0`, `0`</span>
                        <span class="sa">f</span><span class="s1">&#39;output_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">_</span><span class="si">{</span><span class="n">j</span><span class="si">}</span><span class="s1">&#39;</span> <span class="p">:</span> <span class="n">output_tensor</span><span class="p">,</span> <span class="c1"># i.e. `predictions_0_0`</span>
                    <span class="p">})</span>

        <span class="k">return</span> <span class="n">outputs</span></div>

<div class="viewcode-block" id="TorchModel.apply_output_operation"><a class="viewcode-back" href="../../../../api/batchflow.models.torch.base.html#batchflow.models.torch.base.TorchModel.apply_output_operation">[docs]</a>    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">apply_output_operation</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">operation</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Apply `operation`, possibly aliased with a string, to `tensor`. &quot;&quot;&quot;</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">operation</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">result</span> <span class="o">=</span> <span class="n">tensor</span>
                <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
            <span class="k">elif</span> <span class="n">operation</span> <span class="o">==</span> <span class="s1">&#39;softplus&#39;</span><span class="p">:</span>
                <span class="n">result</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">softplus</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>
                <span class="n">name</span> <span class="o">=</span> <span class="n">operation</span>
            <span class="k">elif</span> <span class="n">operation</span> <span class="o">==</span> <span class="s1">&#39;sigmoid&#39;</span><span class="p">:</span>
                <span class="n">result</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>
                <span class="n">name</span> <span class="o">=</span> <span class="n">operation</span>
            <span class="k">elif</span> <span class="n">operation</span> <span class="o">==</span> <span class="s1">&#39;proba&#39;</span><span class="p">:</span>
                <span class="n">result</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">name</span> <span class="o">=</span> <span class="n">operation</span>
            <span class="k">elif</span> <span class="n">operation</span> <span class="o">==</span> <span class="s1">&#39;labels&#39;</span><span class="p">:</span>
                <span class="n">result</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">name</span> <span class="o">=</span> <span class="n">operation</span>
            <span class="k">elif</span> <span class="n">callable</span><span class="p">(</span><span class="n">operation</span><span class="p">):</span>
                <span class="n">result</span> <span class="o">=</span> <span class="n">operation</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>
                <span class="n">name</span> <span class="o">=</span> <span class="n">operation</span><span class="o">.</span><span class="vm">__name__</span>
        <span class="k">return</span> <span class="n">result</span><span class="p">,</span> <span class="n">name</span></div>


<div class="viewcode-block" id="TorchModel.prepare_outputs"><a class="viewcode-back" href="../../../../api/batchflow.models.torch.base.html#batchflow.models.torch.base.TorchModel.prepare_outputs">[docs]</a>    <span class="k">def</span> <span class="nf">prepare_outputs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">outputs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Add the hooks to all outputs that look like a layer id. &quot;&quot;&quot;</span>
        <span class="n">result</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">output_name</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_layer_id</span><span class="p">(</span><span class="n">output_name</span><span class="p">):</span>
                <span class="n">layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_layer</span><span class="p">(</span><span class="n">output_name</span><span class="p">)</span>
                <span class="n">hook</span> <span class="o">=</span> <span class="n">LayerHook</span><span class="p">(</span><span class="n">layer</span><span class="p">)</span>
                <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">hook</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output_name</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">result</span></div>

<div class="viewcode-block" id="TorchModel.extract_outputs"><a class="viewcode-back" href="../../../../api/batchflow.models.torch.base.html#batchflow.models.torch.base.TorchModel.extract_outputs">[docs]</a>    <span class="k">def</span> <span class="nf">extract_outputs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">output_container</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Retrieve activation data from hooks, get other requested outputs from container. &quot;&quot;&quot;</span>
        <span class="n">requested_outputs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">LayerHook</span><span class="p">):</span>
                <span class="n">item</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
                <span class="n">value</span> <span class="o">=</span> <span class="n">item</span><span class="o">.</span><span class="n">activation</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">value</span> <span class="o">=</span> <span class="n">output_container</span><span class="p">[</span><span class="n">item</span><span class="p">]</span>

            <span class="n">requested_outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">requested_outputs</span></div>


    <span class="c1"># Preserve model for later usage</span>
<div class="viewcode-block" id="TorchModel.save"><a class="viewcode-back" href="../../../../api/batchflow.models.torch.base.html#batchflow.models.torch.base.TorchModel.save">[docs]</a>    <span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Save torch model.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        path : str</span>
<span class="sd">            Path to a file where the model data will be stored.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        .. code-block:: python</span>

<span class="sd">            torch_model = ResNet34()</span>

<span class="sd">        Now save the model</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            torch_model.save(&#39;/path/to/models/resnet34&#39;)</span>

<span class="sd">        The model will be saved to /path/to/models/resnet34.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">_</span> <span class="o">=</span> <span class="n">args</span>
        <span class="n">dirname</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">dirname</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">dirname</span><span class="p">):</span>
            <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">dirname</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;pickle_module&#39;</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;pickle_module&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">dill</span>

        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">({</span><span class="n">item</span><span class="p">:</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">)</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">PRESERVE</span><span class="p">},</span> <span class="n">path</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

<div class="viewcode-block" id="TorchModel.load"><a class="viewcode-back" href="../../../../api/batchflow.models.torch.base.html#batchflow.models.torch.base.TorchModel.load">[docs]</a>    <span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="nb">eval</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Load a torch model from files.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        path : str</span>
<span class="sd">            File path where a model is stored.</span>

<span class="sd">        eval : bool</span>
<span class="sd">            Whether to switch the model to eval mode.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        .. code-block:: python</span>

<span class="sd">            resnet = ResNet34(load=dict(path=&#39;/path/to/models/resnet34&#39;))</span>

<span class="sd">            torch_model.load(path=&#39;/path/to/models/resnet34&#39;)</span>

<span class="sd">            TorchModel(config={&#39;device&#39;: &#39;gpu:2&#39;, &#39;load/path&#39;: &#39;/path/to/models/resnet34&#39;})</span>

<span class="sd">        **How to move the model to device**</span>

<span class="sd">        The model will be moved to device specified in the model config by key `device`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">_</span> <span class="o">=</span> <span class="n">args</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_parse_devices</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;pickle_module&#39;</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;pickle_module&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">dill</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">:</span>
            <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="c1"># `load_config` is a reference to `self.external_config` used to update `config`</span>
        <span class="c1"># It is required since `self.external_config` is overwritten in the cycle below</span>
        <span class="n">load_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">external_config</span>

        <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">PRESERVE</span><span class="p">:</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">,</span> <span class="n">checkpoint</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">item</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">+</span> <span class="n">load_config</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">model_to_device</span><span class="p">()</span>

        <span class="k">if</span> <span class="nb">eval</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span></div>


    <span class="c1"># Debug and profile the performance</span>
<div class="viewcode-block" id="TorchModel.set_debug_mode"><a class="viewcode-back" href="../../../../api/batchflow.models.torch.base.html#batchflow.models.torch.base.TorchModel.set_debug_mode">[docs]</a>    <span class="k">def</span> <span class="nf">set_debug_mode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Changes representation of model to a more or less detailed.</span>
<span class="sd">        By default, model representation reduces the description of the most complex modules.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Model is not initialized yet. &#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">module</span><span class="p">:</span> <span class="nb">setattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="s1">&#39;debug&#39;</span><span class="p">,</span> <span class="n">mode</span><span class="p">))</span></div>

<div class="viewcode-block" id="TorchModel.show_profile_info"><a class="viewcode-back" href="../../../../api/batchflow.models.torch.base.html#batchflow.models.torch.base.TorchModel.show_profile_info">[docs]</a>    <span class="k">def</span> <span class="nf">show_profile_info</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">per_iter</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">sortby</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">limit</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">parse</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Show stored profiling information with varying levels of details. &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">profile_info</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">or</span> <span class="n">parse</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_parse_profilers</span><span class="p">()</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s1">&#39;cpu&#39;</span><span class="p">:</span>
            <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;ncalls&#39;</span><span class="p">,</span> <span class="s1">&#39;CPU_tottime&#39;</span><span class="p">,</span> <span class="s1">&#39;CPU_cumtime&#39;</span><span class="p">,</span> <span class="s1">&#39;CPU_tottime_avg&#39;</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">sortby</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">sortby</span> <span class="o">=</span> <span class="p">(</span><span class="s1">&#39;CPU_tottime&#39;</span><span class="p">,</span> <span class="s1">&#39;sum&#39;</span><span class="p">)</span> <span class="k">if</span> <span class="n">per_iter</span> <span class="ow">is</span> <span class="kc">False</span> <span class="k">else</span> <span class="s1">&#39;CPU_tottime&#39;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;ncalls&#39;</span><span class="p">,</span> <span class="s1">&#39;CUDA_cumtime&#39;</span><span class="p">,</span> <span class="s1">&#39;CUDA_cumtime_avg&#39;</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">sortby</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">sortby</span> <span class="o">=</span> <span class="p">(</span><span class="s1">&#39;CUDA_cumtime&#39;</span><span class="p">,</span> <span class="s1">&#39;sum&#39;</span><span class="p">)</span> <span class="k">if</span> <span class="n">per_iter</span> <span class="ow">is</span> <span class="kc">False</span> <span class="k">else</span> <span class="s1">&#39;CUDA_cumtime&#39;</span>

        <span class="k">if</span> <span class="n">per_iter</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
            <span class="n">aggs</span> <span class="o">=</span> <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;sum&#39;</span><span class="p">,</span> <span class="s1">&#39;mean&#39;</span><span class="p">,</span> <span class="s1">&#39;max&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">columns</span><span class="p">}</span>
            <span class="n">result</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">profile_info</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="s1">&#39;name&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">agg</span><span class="p">(</span><span class="n">aggs</span><span class="p">)</span>
                      <span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">sortby</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)[:</span><span class="n">limit</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">profile_info</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span><span class="o">.</span><span class="n">set_index</span><span class="p">([</span><span class="s1">&#39;iter&#39;</span><span class="p">,</span> <span class="s1">&#39;name&#39;</span><span class="p">])[</span><span class="n">columns</span><span class="p">]</span>
                      <span class="o">.</span><span class="n">sort_values</span><span class="p">([</span><span class="s1">&#39;iter&#39;</span><span class="p">,</span> <span class="n">sortby</span><span class="p">],</span> <span class="n">ascending</span><span class="o">=</span><span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">])</span>
                      <span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">df</span><span class="p">:</span> <span class="n">df</span><span class="p">[:</span><span class="n">limit</span><span class="p">])</span><span class="o">.</span><span class="n">droplevel</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">result</span></div>

    <span class="k">def</span> <span class="nf">_parse_profilers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">us_in_s</span> <span class="o">=</span> <span class="mf">1000.0</span> <span class="o">*</span> <span class="mf">1000.0</span>

        <span class="n">indices</span><span class="p">,</span> <span class="n">values</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">profiler</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">profilers</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">evt</span> <span class="ow">in</span> <span class="n">profiler</span><span class="o">.</span><span class="n">function_events</span><span class="o">.</span><span class="n">key_averages</span><span class="p">():</span>
                <span class="n">indices</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">i</span><span class="p">,</span> <span class="n">evt</span><span class="o">.</span><span class="n">key</span><span class="p">))</span>
                <span class="n">row_dict</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="s1">&#39;ncalls&#39;</span><span class="p">:</span> <span class="n">evt</span><span class="o">.</span><span class="n">count</span><span class="p">,</span>
                    <span class="s1">&#39;CPU_tottime&#39;</span><span class="p">:</span> <span class="n">evt</span><span class="o">.</span><span class="n">self_cpu_time_total</span> <span class="o">/</span> <span class="n">us_in_s</span><span class="p">,</span>
                    <span class="s1">&#39;CPU_cumtime&#39;</span><span class="p">:</span> <span class="n">evt</span><span class="o">.</span><span class="n">cpu_time_total</span> <span class="o">/</span> <span class="n">us_in_s</span><span class="p">,</span>
                    <span class="s1">&#39;CUDA_cumtime&#39;</span><span class="p">:</span> <span class="n">evt</span><span class="o">.</span><span class="n">cuda_time_total</span> <span class="o">/</span> <span class="n">us_in_s</span><span class="p">,</span>
                <span class="p">}</span>
                <span class="n">values</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">row_dict</span><span class="p">)</span>
        <span class="n">multiindex</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">MultiIndex</span><span class="o">.</span><span class="n">from_tuples</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;iter&#39;</span><span class="p">,</span> <span class="s1">&#39;name&#39;</span><span class="p">])</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">profile_info</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">multiindex</span><span class="p">,</span>
                                         <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;ncalls&#39;</span><span class="p">,</span> <span class="s1">&#39;CPU_tottime&#39;</span><span class="p">,</span> <span class="s1">&#39;CPU_cumtime&#39;</span><span class="p">,</span> <span class="s1">&#39;CUDA_cumtime&#39;</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">profile_info</span><span class="p">[</span><span class="s1">&#39;CPU_tottime_avg&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">profile_info</span><span class="p">[</span><span class="s1">&#39;CPU_tottime&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">profile_info</span><span class="p">[</span><span class="s1">&#39;ncalls&#39;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">profile_info</span><span class="p">[</span><span class="s1">&#39;CUDA_cumtime_avg&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">profile_info</span><span class="p">[</span><span class="s1">&#39;CUDA_cumtime&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">profile_info</span><span class="p">[</span><span class="s1">&#39;ncalls&#39;</span><span class="p">]</span></div>
</pre></div>

           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2017-2021, Analysis Center.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>